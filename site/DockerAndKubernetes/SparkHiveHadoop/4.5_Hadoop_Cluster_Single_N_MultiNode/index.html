<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../../img/favicon.ico">
        <title>Hadoop Cluster - My Docs</title>
        <link href="../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../css/fontawesome.min.css" rel="stylesheet">
        <link href="../../../css/brands.min.css" rel="stylesheet">
        <link href="../../../css/solid.min.css" rel="stylesheet">
        <link href="../../../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../../../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../../..">My Docs</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="nav-item">
                                <a href="../../.." class="nav-link">Welcome to MkDocs</a>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Airflow</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../Airflow/1.0.0_AirFlow_Concepts/" class="dropdown-item">Airflow Concepts</a>
</li>
                                    
<li>
    <a href="../../../Airflow/1.0.1_A_Dags_Anatomy/" class="dropdown-item">A dags anatomy</a>
</li>
                                    
<li>
    <a href="../../../Airflow/1.0.2_Hello_Airflow/" class="dropdown-item">Hello-Airflow</a>
</li>
                                    
<li>
    <a href="../../../Airflow/1.0.3_Airflow_Dbt_Docker/" class="dropdown-item">Project Airflow dbt</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">DE Projects</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../DE-Projects/Csv-To-MSSQL/" class="dropdown-item">Python - CSV To MSSQL</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/CurrencyPredictor/" class="dropdown-item">CurrencyPredictor</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Dbrk-E2E-AttritionProject/" class="dropdown-item">Problem Statement</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Download-Haddop-Jars/" class="dropdown-item">Download JARs-Apache Maven Repo</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/FetchJsonWriteParquet/" class="dropdown-item">Json To Parquet Using Spark And Azure</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/InstallScala/" class="dropdown-item">Scala Install</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/JsonFlatAzureSDK/" class="dropdown-item">Flatten Json Using Azure SDK</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/LocalPython_AzureBlob/" class="dropdown-item">Local Python Code to Rearrange Files in a Azure Blob Container</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Microsoft_OpenJDK/" class="dropdown-item">Microsoft OpenJDK</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Project_MigrationToAzureBlob/" class="dropdown-item">CMS Migration to Azure Blob</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Project_MongoCMS/" class="dropdown-item">CMS using MongoDB</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Project_SSRS_SSIS_SharePoint/" class="dropdown-item">Project - ETL and Reporting Lending Org</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Raw-Json-To-Hive/" class="dropdown-item">Raw Json To Hive</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/SPY_ETF_Buy_Recommender/" class="dropdown-item">SPY ETF Buy Recommender</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">AzureSkyWeather</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/AzureSkyWeather/HomeProjectAzureSkyWeather/" class="dropdown-item">Project AzureSkyWeather</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">1 Ingestion</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">HttpTriggered</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/AzureSkyWeather/1_Ingestion/HttpTriggered/HTTPTriggered_AzureFunc/" class="dropdown-item">Part 1A - Using Azure HTTP-Triggered Function</a>
</li>
            
<li>
    <a href="../../../DE-Projects/AzureSkyWeather/1_Ingestion/HttpTriggered/nav2_AzureFunctions/" class="dropdown-item">Azure Functions Quickstart</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">TimerTriggered</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/AzureSkyWeather/1_Ingestion/TimerTriggered/TimerTriggered_AzureFunc/" class="dropdown-item">Part 1B - Using Azure Timer-Triggered Function</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">2 Transformation</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/AzureSkyWeather/2_Transformation/Solution_Details/" class="dropdown-item">Solution Details</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">JsonValidator</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/JsonValidator/AzureFunction-ValidateJSOns/" class="dropdown-item">Azure Functions - Validate JSONs</a>
</li>
            
<li>
    <a href="../../../DE-Projects/JsonValidator/Python-ValidateJSONs/" class="dropdown-item">Validate JSON using Python</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Sparkzure</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/Sparkzure/HomeProjectSparkzure/" class="dropdown-item">Project Sparkzure</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">StreamKraft</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/StreamKraft/HomeProjectStreamKraft/" class="dropdown-item">Project StreamKraft</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">DevOps</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../DevOps/1.1_Hello_GitHub_Actions_Workflow/" class="dropdown-item">Hello GitHub Actions Workflow</a>
</li>
                                    
<li>
    <a href="../../../DevOps/1.1_Sample_Workflows/" class="dropdown-item">Sample Workflows</a>
</li>
                                    
<li>
    <a href="../../../DevOps/1_GitHub-Concepts/" class="dropdown-item">GitHub Concepts</a>
</li>
                                    
<li>
    <a href="../../../DevOps/2.1_Self-Hosted_Agent_Windows/" class="dropdown-item">Self-Hosted-Agent-Windows</a>
</li>
                                    
<li>
    <a href="../../../DevOps/2.2_Self-Hosted_Agent_Windows_Container/" class="dropdown-item">Self-Hosted-Agent-Win-Container</a>
</li>
                                    
<li>
    <a href="../../../DevOps/2.3_Self-Hosted_Agent_Linux_Container/" class="dropdown-item">Self-Hosted-Agent-Ubuntu-Container</a>
</li>
                                    
<li>
    <a href="../../../DevOps/2_Azure-Pipelines/" class="dropdown-item">Azure-Pipelines</a>
</li>
                                    
<li>
    <a href="../../../DevOps/ADF_CICD/" class="dropdown-item">ADF-CI-CD</a>
</li>
                                    
<li>
    <a href="../../../DevOps/Biceps/" class="dropdown-item">What is Bicep?</a>
</li>
                                    
<li>
    <a href="../../../DevOps/CI-CD_in%20ADF/" class="dropdown-item">CI CD in ADF</a>
</li>
                                    
<li>
    <a href="../../../DevOps/GitScenarios/" class="dropdown-item">GitScenarios</a>
</li>
                                    
<li>
    <a href="../../../DevOps/JenkinsVsGitHubVsAzureDevOps/" class="dropdown-item">Jenkins Vs GitHub Vs Devops</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle active" aria-current="page" role="button" data-bs-toggle="dropdown"  aria-expanded="false">DockerAndKubernetes</a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">AirflowDocker</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../AirflowDocker/1_AirflowDocker/" class="dropdown-item">Airflow</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Kafka</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../Kafka/2_Confluent%20Kafka/" class="dropdown-item">Confluent Kafka</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Mongodb</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../Mongodb/3_DockerMongodb/" class="dropdown-item">MongoDB</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">SparkHiveHadoop</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../4.1_PySpark/" class="dropdown-item">PySpark</a>
</li>
            
<li>
    <a href="../4.2_Bitnami_Spark_Cluster/" class="dropdown-item">Bitnami Spark</a>
</li>
            
<li>
    <a href="../4.3_VSCode_Docker_Connection/" class="dropdown-item">VSCode-Docker-Connection</a>
</li>
            
<li>
    <a href="../4.4_Spark_Hive_MSSQL/" class="dropdown-item">Spark-Hive_MSSQL</a>
</li>
            
<li>
    <a href="./" class="dropdown-item active" aria-current="page">Hadoop Cluster</a>
</li>
            
<li>
    <a href="../4.6_Hive_Hadooop_Postgres_Presto/" class="dropdown-item">bde2020-Hive-Hadoop-Presto</a>
</li>
            
<li>
    <a href="../4.7_Hadoop_Hive_SingleNode_MySQL/" class="dropdown-item">Hive-Hadoop-MySQL-SingleNode</a>
</li>
            
<li>
    <a href="../4.8_Hive-ApacheOfficial/" class="dropdown-item">Hive Official Setup</a>
</li>
            
<li>
    <a href="../4.9.1_Hive_Concepts/" class="dropdown-item">Hive Concepts</a>
</li>
            
<li>
    <a href="../4.9.2_Hadoop_Concepts/" class="dropdown-item">Hadoop Concepts</a>
</li>
            
<li>
    <a href="../4.9_DockerConcepts/" class="dropdown-item">Docker Misc Concepts</a>
</li>
            
<li>
    <a href="../4_Spark-Hive-Hadoop/" class="dropdown-item">4 Spark Hive Hadoop</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">M365</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../M365/DocumentumToSharePoint/" class="dropdown-item">Documentum-SharePoint Online</a>
</li>
                                    
<li>
    <a href="../../../M365/LicensingExamples/" class="dropdown-item">M365 Licensing Examples</a>
</li>
                                    
<li>
    <a href="../../../M365/SPMT/" class="dropdown-item">SPMT - SharePoint Migration</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePoint2007FarmUpgrade/" class="dropdown-item">SharePoint Farm Upgrade</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePoint2016FarmUpgrade/" class="dropdown-item">SharePoint Farm 2016 Farm Setup</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePointEvents/" class="dropdown-item">SharePoint Event Receiver</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePointFarmConsolidation/" class="dropdown-item">SharePoint Farm Consolidation</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePointFormsOrPowerApps/" class="dropdown-item">SharePoint Forms or PowerApps</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePointMiniRole/" class="dropdown-item">SharePoint Mini Role</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePointVersionEvolution/" class="dropdown-item">SharePoint Evolution</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePointVsOtherECM/" class="dropdown-item">SharePoint vs Other ECMS</a>
</li>
                                    
<li>
    <a href="../../../M365/WSS3DocumentUpload/" class="dropdown-item">Project - C# - WSS 3 Bulk ingestion</a>
</li>
                                    
<li>
    <a href="../../../M365/oAuthSharePointPython/" class="dropdown-item">Python-oAuth-SharePointOnline</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Microsoft Fabric</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../Microsoft-Fabric/DataFactory/" class="dropdown-item">Pipelines&DataFlows</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/DataScience/" class="dropdown-item">Data Science on Fabric Overview</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/DataWareHouse/" class="dropdown-item">DataWareHouse</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/DirectLake/" class="dropdown-item">DirectLake|Fabric|PowerBI</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/E2EProject/" class="dropdown-item">E2EProject</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/ETL-OPG-Copydata-JSON-Lakehouse/" class="dropdown-item">JSON-DeltaLake-OPG</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/ETL-Pyspark-Notebook-Lakehouse/" class="dropdown-item">ETL-Load data into Lakehouse - Pyspark Notebook</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/FabricAdministration/" class="dropdown-item">Administration</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/FabricQ%26A/" class="dropdown-item">Fabric Q&A</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/FabricSparkStreaming/" class="dropdown-item">Spark Streaming</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/HelloMicrosoftFabric/" class="dropdown-item">Hello Fabric</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/InspectingDataframes/" class="dropdown-item">Whats in your df?</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/KQL/" class="dropdown-item">KQL</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/PandasVsSparkDf/" class="dropdown-item">PandasVsSparkDf</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/Pyspark_SparkSQL/" class="dropdown-item">Pyspark|SparkSQL CheatSheet</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/RealTimeAnalytics/" class="dropdown-item">Real-time Intelligence</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Misc</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../Misc/10_Fact_vs_Dimension_tables/" class="dropdown-item">Fact Vs Dimension Table</a>
</li>
                                    
<li>
    <a href="../../../Misc/1_GoogleCloudSeeUsage/" class="dropdown-item">Check Google Usage</a>
</li>
                                    
<li>
    <a href="../../../Misc/2_InstallVMWareFree/" class="dropdown-item">VMWare For Free</a>
</li>
                                    
<li>
    <a href="../../../Misc/3_Markdown/" class="dropdown-item">Markdown</a>
</li>
                                    
<li>
    <a href="../../../Misc/4_VSTrics/" class="dropdown-item">Visual Studio Code Tricks</a>
</li>
                                    
<li>
    <a href="../../../Misc/5_WhichDatastsToUse/" class="dropdown-item">Free Datasets for Data Practice</a>
</li>
                                    
<li>
    <a href="../../../Misc/6_RunningAppsInBg/" class="dropdown-item">Running Service in Background</a>
</li>
                                    
<li>
    <a href="../../../Misc/7_Azure_Budget/" class="dropdown-item">How to set a Azure Budget</a>
</li>
                                    
<li>
    <a href="../../../Misc/9_WhyUbuntuIsGood/" class="dropdown-item">Why Ubuntu is good to learn</a>
</li>
                                    
<li>
    <a href="../../../Misc/markdown_pdf_export_html/" class="dropdown-item">Markdown pdf export html</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">MarkdownColor.md</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Misc/MarkdownColor.md/Color/" class="dropdown-item">Color Reference</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Images</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Misc/MarkdownColor.md/images/Color/" class="dropdown-item">Color Palettes</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">MongoDB</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../MongoDB/HowMongoDBStoresFiles/" class="dropdown-item">How MongoDB Stores Data</a>
</li>
                                    
<li>
    <a href="../../../MongoDB/MongbDB_Vs_Atlas_VsCosmosDB/" class="dropdown-item">MongoDB Vs CosmosDB</a>
</li>
                                    
<li>
    <a href="../../../MongoDB/MongoDBCommands/" class="dropdown-item">MongoDB Commands</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">PowerPlatform</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../PowerPlatform/CalculationGroups/" class="dropdown-item">CalculationGroups</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/CustomConnectors/" class="dropdown-item">Building Custom Connectors</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/ECMCaptureFlow/" class="dropdown-item">Power Automate Or Kofax/Captiva?</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/EnableMicrosoftSyntex/" class="dropdown-item">Enable Microsoft Syntex on your Office 365 tenant</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/EnableSyntexOnYourDocumentLibrary/" class="dropdown-item">Create a model on SharePoint - Syntex</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/GoogleProviderPowerPages/" class="dropdown-item">Google Authentication</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/HealthClinicDataverseSecurity/" class="dropdown-item">HealthClinicDataverseSecurity</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/HelloDataverse/" class="dropdown-item">Hello Dataverse</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/HelloDynamics365/" class="dropdown-item">Dynamics 365 Ecosystem</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/HelloPowerPlatform/" class="dropdown-item">PowerPlatform Ecosystem</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/ModelDrivenApps/" class="dropdown-item">Model-Driven Apps</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/OnPremiseGateway/" class="dropdown-item">Onpremise Gateway</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/PowerAutomateIsWorkflowTeams/" class="dropdown-item">Workflow is Power Automate</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/PowerPlatformAdminCentral/" class="dropdown-item">PowerPlatformAdminCentral</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/PowerPlatformQ%26A/" class="dropdown-item">Pl-900-Q&A</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">DocumentIntelligence</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../PowerPlatform/DocumentIntelligence/AAIDI_AzureCognitiveSearch/" class="dropdown-item">Integrate AI Search and Azure AI Document Intelligence</a>
</li>
            
<li>
    <a href="../../../PowerPlatform/DocumentIntelligence/AAIDI_Q%26A/" class="dropdown-item">AAIDI Q&A</a>
</li>
            
<li>
    <a href="../../../PowerPlatform/DocumentIntelligence/AzureAIDocumentIntelligence/" class="dropdown-item">Azure AI Document Intelligence</a>
</li>
            
<li>
    <a href="../../../PowerPlatform/DocumentIntelligence/DocumentAutomation/" class="dropdown-item">Document automation base kit</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Python</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../Python/1.0_Sets/" class="dropdown-item">Sets</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.0_assert_methods/" class="dropdown-item">assert methods</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.1_decorators/" class="dropdown-item">decorators</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.2_argv/" class="dropdown-item">argv</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.3_Diff_And_Patch/" class="dropdown-item">diffAndpatch</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.3_error_handling/" class="dropdown-item">Error Handling</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.4_pdb/" class="dropdown-item">pdb</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.5_pyformat/" class="dropdown-item">format method</a>
</li>
                                    
<li>
    <a href="../../../Python/1.10_Func_Modl_Summary/" class="dropdown-item">LFM Summary</a>
</li>
                                    
<li>
    <a href="../../../Python/1.11_ifelifelse/" class="dropdown-item">ifelifelse</a>
</li>
                                    
<li>
    <a href="../../../Python/1.12_Operators/" class="dropdown-item">operators</a>
</li>
                                    
<li>
    <a href="../../../Python/1.13_For_Loops/" class="dropdown-item">for loops</a>
</li>
                                    
<li>
    <a href="../../../Python/1.14_enumerate/" class="dropdown-item">1.14 enumerate</a>
</li>
                                    
<li>
    <a href="../../../Python/1.15_range_function/" class="dropdown-item">range function</a>
</li>
                                    
<li>
    <a href="../../../Python/1.16_built_in_functions/" class="dropdown-item">1.16 built in functions</a>
</li>
                                    
<li>
    <a href="../../../Python/1.17_withStatement/" class="dropdown-item">with statement</a>
</li>
                                    
<li>
    <a href="../../../Python/1.18_unittest_pytest/" class="dropdown-item">pytest</a>
</li>
                                    
<li>
    <a href="../../../Python/1.19_if_name_main.md/" class="dropdown-item">if__name__main</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1_Tuples/" class="dropdown-item">Tuples</a>
</li>
                                    
<li>
    <a href="../../../Python/1.2_Tuples_Advanced/" class="dropdown-item">Advanced Tuples</a>
</li>
                                    
<li>
    <a href="../../../Python/1.3_List/" class="dropdown-item">1.3 List</a>
</li>
                                    
<li>
    <a href="../../../Python/1.4_Dictionaries/" class="dropdown-item">1.4 Dictionaries</a>
</li>
                                    
<li>
    <a href="../../../Python/1.5_Lamda_Functions/" class="dropdown-item">Lamda Functions</a>
</li>
                                    
<li>
    <a href="../../../Python/1.9_Func_Modl_Lib/" class="dropdown-item">Library-Modules-Funcs</a>
</li>
                                    
<li>
    <a href="../../../Python/1_Python/" class="dropdown-item">Python</a>
</li>
                                    
<li>
    <a href="../../../Python/Linux/" class="dropdown-item">Essential Unix Commands</a>
</li>
                                    
<li>
    <a href="../../../Python/Pyspark/" class="dropdown-item">PySpark</a>
</li>
                                    
<li>
    <a href="../../../Python/PythonScripts/" class="dropdown-item">Python Sample Scripts</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">GraphAPIJupyter</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Python/GraphAPIJupyter/GraphAPIUsingJuputer/" class="dropdown-item">Graph API - Juputer</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">SQL</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../SQL/1.0.0_dbt/" class="dropdown-item">dbt</a>
</li>
                                    
<li>
    <a href="../../../SQL/1.0.1_setup_simple_dbt_project/" class="dropdown-item">1.0.1 setup simple dbt project</a>
</li>
                                    
<li>
    <a href="../../../SQL/FlatFileSoure/" class="dropdown-item">FlatFileSoure</a>
</li>
                                    
<li>
    <a href="../../../SQL/InputAndOutputProperties/" class="dropdown-item">Understanding External Columns and Output Columns in SSIS</a>
</li>
                                    
<li>
    <a href="../../../SQL/MSSQL_Versions/" class="dropdown-item">SQL Server Versions</a>
</li>
                                    
<li>
    <a href="../../../SQL/Project_1-ETL-CSV-MSSQL/" class="dropdown-item">Project 1 - ETL Flat Files to MSSQL</a>
</li>
                                    
<li>
    <a href="../../../SQL/Project_2-UsingWebServicesInSSIS/" class="dropdown-item">Project 2 - Web Service SSIS Script Task</a>
</li>
                                    
<li>
    <a href="../../../SQL/SQL/" class="dropdown-item">Spark-SQL</a>
</li>
                                    
<li>
    <a href="../../../SQL/SQL_AdvancedTopics/" class="dropdown-item">SQL Advanced Topics</a>
</li>
                                    
<li>
    <a href="../../../SQL/SSIS/" class="dropdown-item">SQL Server Integration Services</a>
</li>
                                    
<li>
    <a href="../../../SQL/SSRS/" class="dropdown-item">SSRS</a>
</li>
                                    
<li>
    <a href="../../../SQL/Windows_Functions/" class="dropdown-item">Window Functions</a>
</li>
                                    
<li>
    <a href="../../../SQL/connecting-with-dbt/" class="dropdown-item">Connect Local dbt with MSSQL Server</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Spark DataBricks</a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">1.0 Spark</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.0_Spark-Concepts/" class="dropdown-item">Spark</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.10_Scala_Cheatsheet/" class="dropdown-item">Scala Cheatsheet</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.11_Spark_Interview_Questions/" class="dropdown-item">Spark Interview Questions</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.12_Spark_Shuffle/" class="dropdown-item">Shuffle in Spark</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.13_SparkDatabaseTablesCatalogsMetastore/" class="dropdown-item">Spark DB-Tables-Metastore-Catalogs</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.14_Q%26A/" class="dropdown-item">Q&A</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.15_CommonPysparkTopics/" class="dropdown-item">PySpark Concepts I</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.16_ConnectingSparkToHive/" class="dropdown-item">Spark-Hive-Delta Connection</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.1_NarrowVsWideTransformation/" class="dropdown-item">Narrow_Vs_Wide_Transformation</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.2_SparkArchitecture/" class="dropdown-item">Spark Architecture</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.3_persist_and_cache/" class="dropdown-item">persist and cache</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.4_broadcastvariables/" class="dropdown-item">Broadcast Variables</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.5_DataSkewHandling/" class="dropdown-item">Data Skew in Spark</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.6_dropna_fillna_df_missing_val_handling/" class="dropdown-item">dropna and fillna</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.7_distinct_dropDuplicate_windowsFunc/" class="dropdown-item">Removing Duplicates - PySpark</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.8_Partition_Grouping/" class="dropdown-item">Partition And Bucket</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.9_RDD_Dataframe_Dataset/" class="dropdown-item">RDD-Dataframe-Dataset</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Install Pyspark Windows</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/Install-Pyspark-Windows/Install-Pyspark-Windows/" class="dropdown-item">Install-PySpark-Windows</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">2.0 Spark To ADLS</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Spark-DataBricks/2.0_Spark_To_ADLS/2.0_Spark_To_ADLS/" class="dropdown-item">Spark-To-ADLS-Connection</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/2.0_Spark_To_ADLS/2.1_Spark-To_ADLS_Summary/" class="dropdown-item">Spark-To-ADLS-Summary</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">3.0 Databricks</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.0_Databricks_Concepts/" class="dropdown-item">Databricks</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.1_Catalogs_And_Metastore/" class="dropdown-item">Hive Metastore and the hive_metastore folder</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.2_AuthenticationMethods/" class="dropdown-item">Authentication Method</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.3_Mount_ADLS_on_Databricks/" class="dropdown-item">Mount ADLS on Databricks</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.4_Databricks_Secret_Scope/" class="dropdown-item">Secret Scope</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.5_Databricks_SQL/" class="dropdown-item">CREATE TABLE USING</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.6_DatabricksMagicCommands/" class="dropdown-item">Magic Commands</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.7_DeltaLake_And_Lakehouse/" class="dropdown-item">Delta Lake And Lakehouse</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/4.8_Databricks_ProjectA1/" class="dropdown-item">Project-A</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">4.0 Hive</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Spark-DataBricks/4.0_Hive/Hive_Concepts/" class="dropdown-item">Hive Concepts</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">StreamProcessing</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../StreamProcessing/1.0_What_Is_Stream_Processing/" class="dropdown-item">1.0 What Is Stream Processing</a>
</li>
                                    
<li>
    <a href="../../../StreamProcessing/2.0.1_EventHubs_Vs_Kafka/" class="dropdown-item">EventHubs Vs Kafka</a>
</li>
                                    
<li>
    <a href="../../../StreamProcessing/2.0.2_Project_Hello_EventHubs/" class="dropdown-item">Overview</a>
</li>
                                    
<li>
    <a href="../../../StreamProcessing/2.0.3_EventHubsLocalEmulator/" class="dropdown-item">Event Hubs Emulator - End to End</a>
</li>
                                    
<li>
    <a href="../../../StreamProcessing/2.0_Azure_EventHubs/" class="dropdown-item">EventHubs</a>
</li>
                                    
<li>
    <a href="../../../StreamProcessing/4_EventProcessingChoices/" class="dropdown-item">Stream Processing Product Combination</a>
</li>
                                    
<li>
    <a href="../../../StreamProcessing/5_AmazonKinesisSparkIntegration/" class="dropdown-item">5 AmazonKinesisSparkIntegration</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Synapse ADF</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../Synapse-ADF/1.0_SynapseConcepts/" class="dropdown-item">SynapseConcepts</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.1_Pools/" class="dropdown-item">Pools</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.3_ETL%20Pipelines/" class="dropdown-item">ETL Pipelines</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.4_Copy-data-tool/" class="dropdown-item">ADF Copy task - When to use</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.5_IntegrationRuntime/" class="dropdown-item">Integration Runtime</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.6_DB_Types_In_Synapse/" class="dropdown-item">Types of DB in Synapse</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.7_SynapseLakeDBAndLakehouse/" class="dropdown-item">Lake DB-Lakehouse-Delta Lake</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.8_ADF_SA_Evolution/" class="dropdown-item">ADF & Synapse Evolution</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.9_CETAS/" class="dropdown-item">CETAS</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/2.0_Projects/" class="dropdown-item">2.0 Projects</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/2.1_Pipeline-Local-ADLS/" class="dropdown-item">CopyData-LocalToADLS</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/2.2_PySparkWarehouse/" class="dropdown-item">PysparkWarehouse</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/2.3_ADF_RestAPI_Databricks/" class="dropdown-item">2.3 ADF RestAPI Databricks</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/2.4_Monitor_ADF_Pipelines/" class="dropdown-item">ADF Pipelines Monitoring</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/2.5_ADF_Pipeline_Copy/" class="dropdown-item">Export ADF Pipeline</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/Q%26A/" class="dropdown-item">100 Synapse FAQs</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../4.4_Spark_Hive_MSSQL/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../4.6_Hive_Hadooop_Postgres_Presto/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#create-a-seven-node-hadoop-container-on-docker" class="nav-link">Create a Seven-Node Hadoop Container on Docker</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#introduction" class="nav-link">Introduction</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#prerequisites" class="nav-link">Prerequisites</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#files-used" class="nav-link">Files Used</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#step-1-prepare-the-docker-environment" class="nav-link">Step 1: Prepare the Docker Environment</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#step-2-build-and-start-the-cluster" class="nav-link">Step 2: Build and Start the Cluster</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#step-3-verify-the-setup" class="nav-link">Step 3: Verify the Setup</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#conclusion" class="nav-link">Conclusion</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#config-reference" class="nav-link">Config reference</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#reference" class="nav-link">Reference</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#create-a-single-node-hadoop-container-on-docker" class="nav-link">Create a Single-Node Hadoop Container on Docker</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#quick-steps-for-the-busy-people" class="nav-link">Quick Steps for the Busy People</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#detailed-steps-building-the-setup-file-by-file" class="nav-link">Detailed steps - building the setup, file by file</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#use-a-base-image-with-java-8" class="nav-link">Use a base image with Java 8</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#set-environment-variables-for-hadoop" class="nav-link">Set environment variables for Hadoop</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#install-necessary-packages" class="nav-link">Install necessary packages</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#set-root-password" class="nav-link">Set root password</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#create-a-user-dwdas-with-sudo-privileges" class="nav-link">Create a user 'dwdas' with sudo privileges</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#optional-download-and-extract-hadoop-tarball-if-not-already-provided" class="nav-link">Optional: Download and extract Hadoop tarball if not already provided</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#configure-hadoop-create-necessary-directories-on-docker-volumes" class="nav-link">Configure Hadoop - Create necessary directories on Docker volumes</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#copy-configuration-files" class="nav-link">Copy configuration files</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#copy-and-configure-hadoop-envsh-java_home-must-be-set-here-also" class="nav-link">Copy and configure hadoop-env.sh. JAVA_HOME MUST be set here also.</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#set-ownership-for-hadoop-directories-and-volumes-to-dwdas" class="nav-link">Set ownership for Hadoop directories and volumes to 'dwdas'</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#switch-to-the-dwdas-user-for-all-subsequent-operations" class="nav-link">Switch to the dwdas user for all subsequent operations</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#create-the-ssh-directory-and-set-permissions" class="nav-link">Create the .ssh directory and set permissions</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#generate-ssh-keys-for-passwordless-ssh-login-and-configure-ssh" class="nav-link">Generate SSH keys for passwordless SSH login and configure SSH</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#format-hdfs-as-dwdas-user" class="nav-link">Format HDFS as 'dwdas' user</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#expose-the-necessary-ports-for-hadoop-services" class="nav-link">Expose the necessary ports for Hadoop services</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#set-the-container-to-start-in-the-dwdas-users-home-directory" class="nav-link">Set the container to start in the dwdas user's home directory</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#set-the-container-to-start-with-a-bash-shell" class="nav-link">Set the container to start with a bash shell</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#appendix" class="nav-link">Appendix</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#common-errors-and-their-solutions" class="nav-link">Common Errors and Their Solutions</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<ul>
<li><a href="#create-a-seven-node-hadoop-container-on-docker">Create a Seven-Node Hadoop Container on Docker</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#files-used">Files Used</a></li>
<li><a href="#step-1-prepare-the-docker-environment">Step 1: Prepare the Docker Environment</a></li>
<li><a href="#step-2-build-and-start-the-cluster">Step 2: Build and Start the Cluster</a></li>
<li><a href="#step-3-verify-the-setup">Step 3: Verify the Setup</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#config-reference">Config reference</a></li>
<li><a href="#reference">Reference</a></li>
<li><a href="#create-a-single-node-hadoop-container-on-docker">Create a Single-Node Hadoop Container on Docker</a></li>
<li><a href="#quick-steps-for-the-busy-people">Quick Steps for the Busy People</a><ul>
<li><a href="#steps-to-build-the-container-using-ready-to-use-files">Steps to build the container using ready-to-use files</a></li>
<li><a href="#check-the-setup">Check the setup</a></li>
</ul>
</li>
<li><a href="#detailed-steps---building-the-setup-file-by-file">Detailed steps - building the setup, file by file</a><ul>
<li><a href="#details-of-the-files-used">Details of the files used</a></li>
<li><a href="#building-running-and-testing-the-setup">Building, Running, and Testing the Setup</a></li>
<li><a href="#how-to-test-the-setup">How to test the setup?</a></li>
<li><a href="#setup-details">Setup details</a></li>
</ul>
</li>
<li><a href="#appendix">Appendix</a></li>
<li><a href="#common-errors-and-their-solutions">Common Errors and Their Solutions</a></li>
</ul>
<h1 id="create-a-seven-node-hadoop-container-on-docker">Create a Seven-Node Hadoop Container on Docker</h1>
<h2 id="introduction">Introduction</h2>
<p>In this guide, I'll walk through the process of setting up an Apache Hadoop cluster using Docker containers. This setup is ideal for development and testing purposes on your local machine. I'll cover the configuration files, container setup, and how to verify that the cluster is functioning correctly.</p>
<p><strong>For busy people:</strong></p>
<ul>
<li><a href="../Dockerfiles/Hadoop-Docker.zip">Download</a> and unzip the file to a folder</li>
<li>CD and run the following commands
    <code>bash
        docker-compose build
        docker-compose up -d</code></li>
<li>You will have a full-fledged Hadoop setup</li>
</ul>
<p><img alt="" src="../images/2024-08-24-01-44-10.png" /></p>
<h2 id="prerequisites">Prerequisites</h2>
<ul>
<li>Docker installed on your machine.</li>
<li>Basic knowledge of Docker and Hadoop.</li>
</ul>
<h2 id="files-used">Files Used</h2>
<ol>
<li><strong>Dockerfile</strong>: Defines the environment and how the Hadoop services will be run inside the Docker containers.</li>
<li><strong>docker-compose.yml</strong>: Manages the multi-container application, ensuring all necessary Hadoop services are launched and networked correctly.</li>
<li><strong>entrypoint.sh</strong>: A script to start the appropriate Hadoop service based on the container's role (e.g., NameNode, DataNode).</li>
</ol>
<blockquote>
<p><strong>Important</strong>: If you create the <code>entrypoint.sh</code> file on Windows, you must convert it to Unix format using a tool like <a href="https://toolslick.com/conversion/text/dos-to-unix">Toolslick DOS to Unix Converter</a> before using it in your Docker environment.</p>
</blockquote>
<h2 id="step-1-prepare-the-docker-environment">Step 1: Prepare the Docker Environment</h2>
<ol>
<li><strong>Dockerfile</strong>:
   The <code>Dockerfile</code> sets up the Java runtime and Hadoop environment. Here's the Dockerfile used:</li>
</ol>
<p>```Dockerfile
   # Use Java 8 runtime as base image
   FROM openjdk:8-jdk</p>
<p># Set environment variables
   ENV HADOOP_VERSION=2.7.7
   ENV HADOOP_HOME=/usr/local/hadoop
   ENV HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
   ENV PATH=$PATH:$HADOOP_HOME/bin</p>
<p># Install Hadoop
   RUN wget https://archive.apache.org/dist/hadoop/core/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz &amp;&amp; \
       tar -xzvf hadoop-$HADOOP_VERSION.tar.gz &amp;&amp; \
       mv hadoop-$HADOOP_VERSION $HADOOP_HOME &amp;&amp; \
       rm hadoop-$HADOOP_VERSION.tar.gz</p>
<p># Copy and set entrypoint script
   # Note: If entrypoint.sh is created on Windows, convert it to Unix format using dos2unix website.
   COPY entrypoint.sh /entrypoint.sh
   RUN chmod +x /entrypoint.sh</p>
<p># Expose Hadoop ports
   EXPOSE 50070 8088 9000 9864 9870 9866 9867</p>
<p># Set entrypoint
   ENTRYPOINT ["/entrypoint.sh"]
   ```</p>
<ol>
<li><strong>docker-compose.yml</strong>:
   The <code>docker-compose.yml</code> file orchestrates the Hadoop cluster by defining services like NameNode, DataNode, and ResourceManager.</li>
</ol>
<p>```yaml
   version: '3.8'</p>
<p>services:
     namenode:
       build: .
       container_name: namenode
       hostname: namenode
       environment:
         - CLUSTER_NAME=my-hadoop-cluster
       volumes:
         - namenode_data:/hadoop/dfs/name
       ports:
         - "29070:50070"  # HDFS NameNode Web UI on port 29070
         - "29870:9870"   # NameNode Web UI port on port 29870
         - "29000:9000"   # HDFS port on port 29000
       command: namenode
       networks:
         - dasnet</p>
<pre><code> secondarynamenode:
   build: .
   container_name: secondarynamenode
   hostname: secondarynamenode
   volumes:
     - secondarynamenode_data:/hadoop/dfs/secondary
   command: secondarynamenode
   networks:
     - dasnet

 datanode1:
   build: .
   container_name: datanode1
   hostname: datanode1
   volumes:
     - datanode1_data:/hadoop/dfs/data
   command: datanode
   networks:
     - dasnet

 datanode2:
   build: .
   container_name: datanode2
   hostname: datanode2
   volumes:
     - datanode2_data:/hadoop/dfs/data
   command: datanode
   networks:
     - dasnet

 resourcemanager:
   build: .
   container_name: resourcemanager
   hostname: resourcemanager
   ports:
     - "28088:8088"  # ResourceManager Web UI on port 28088
   command: resourcemanager
   networks:
     - dasnet

 nodemanager1:
   build: .
   container_name: nodemanager1
   hostname: nodemanager1
   ports:
     - "29864:9864"  # NodeManager Web UI on port 29864
   command: nodemanager
   networks:
     - dasnet

 historyserver:
   build: .
   container_name: historyserver
   hostname: historyserver
   ports:
     - "29866:9866"  # HistoryServer Web UI on port 29866
     - "29867:9867"  # Additional service on port 29867
   command: historyserver
   networks:
     - dasnet
</code></pre>
<p>volumes:
     namenode_data:
     secondarynamenode_data:
     datanode1_data:
     datanode2_data:</p>
<p>networks:
     dasnet:
       external: true
   ```</p>
<ol>
<li><strong>entrypoint.sh</strong>:
   This script starts the appropriate Hadoop service based on the containers role. Below is the script:</li>
</ol>
<p><code>bash
   #!/bin/bash
   # Format namenode if necessary
   if [ "$1" == "namenode" ]; then
     $HADOOP_HOME/bin/hdfs namenode -format -force -nonInteractive
   fi
   # Start SSH service
   service ssh start
   # Start Hadoop service based on the role
   if [ "$1" == "namenode" ]; then
     $HADOOP_HOME/sbin/hadoop-daemon.sh start namenode
   elif [ "$1" == "datanode" ]; then
     $HADOOP_HOME/sbin/hadoop-daemon.sh start datanode
   elif [ "$1" == "secondarynamenode" ]; then
     $HADOOP_HOME/sbin/hadoop-daemon.sh start secondarynamenode
   elif [ "$1" == "resourcemanager" ]; then
     $HADOOP_HOME/sbin/yarn-daemon.sh start resourcemanager
   elif [ "$1" == "nodemanager" ]; then
     $HADOOP_HOME/sbin/yarn-daemon.sh start nodemanager
   elif [ "$1" == "historyserver" ]; then
     $HADOOP_HOME/sbin/mr-jobhistory-daemon.sh start historyserver
   fi
   # Keep the container running
   tail -f /dev/null</code></p>
<blockquote>
<p><strong>Note</strong>: Convert <code>entrypoint.sh</code> to Unix format if it's created on Windows using <a href="https://toolslick.com/conversion/text/dos-to-unix">Toolslick DOS to Unix Converter</a>.</p>
</blockquote>
<h2 id="step-2-build-and-start-the-cluster">Step 2: Build and Start the Cluster</h2>
<ol>
<li><strong>Build the Docker Images</strong>:</li>
<li>Navigate to the directory containing the <code>Dockerfile</code>, <code>docker-compose.yml</code>, and <code>entrypoint.sh</code> files.</li>
<li>
<p>Run the following command to build the Docker images:
     <code>bash
     docker-compose build</code></p>
</li>
<li>
<p><strong>Start the Cluster</strong>:</p>
</li>
<li>Start the cluster using the following command:
     <code>bash
     docker-compose up -d</code></li>
</ol>
<h2 id="step-3-verify-the-setup">Step 3: Verify the Setup</h2>
<ol>
<li><strong>Access Hadoop Web UIs</strong>:</li>
<li><strong>NameNode Web UI</strong>: <code>http://localhost:29870</code></li>
<li><strong>HDFS NameNode Web UI</strong>: <code>http://localhost:29070</code></li>
<li><strong>ResourceManager Web UI</strong>: <code>http://localhost:28088</code></li>
<li><strong>NodeManager Web UI</strong>: <code>http://localhost:29864</code></li>
<li><strong>HistoryServer Web UI</strong>: <code>http://localhost:29866</code></li>
</ol>
<p>These interfaces will allow you to monitor the status of your Hadoop cluster and the jobs running on it.</p>
<ol>
<li><strong>Run a Test Job</strong>:</li>
<li>
<p><strong>Create Input Directory in HDFS</strong>:
     <code>bash
     docker exec -it namenode /bin/bash
     hdfs dfs -mkdir -p /input
     echo "Hello Hadoop" &gt; /tmp/sample.txt
     hdfs dfs -put /tmp/sample.txt /input/</code></p>
</li>
<li>
<p><strong>Run the WordCount Job</strong>:
     <code>bash
     hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar wordcount /input /output</code></p>
</li>
<li>
<p><strong>Check the Output</strong>:
     <code>bash
     hdfs dfs -cat /output/part-r-00000</code></p>
<p>Expected output:
 <code>Hadoop  1
 Hello   1</code></p>
</li>
</ol>
<h2 id="conclusion">Conclusion</h2>
<p>Remember to convert any scripts created on Windows to Unix format before using them in your Docker containers to avoid potential issues. Happy coding!</p>
<h2 id="config-reference">Config reference</h2>
<table>
<thead>
<tr>
<th><strong>Element</strong></th>
<th><strong>Location/Value</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Hadoop Installation Dir</strong></td>
<td><code>/usr/local/hadoop</code></td>
<td>The directory where Hadoop is installed inside the Docker containers (<code>HADOOP_HOME</code>).</td>
</tr>
<tr>
<td><strong>Hadoop Config Dir</strong></td>
<td><code>/usr/local/hadoop/etc/hadoop</code></td>
<td>Directory containing Hadoop configuration files (<code>HADOOP_CONF_DIR</code>).</td>
</tr>
<tr>
<td><strong>HDFS Data Directory</strong></td>
<td><code>/hadoop/dfs/name</code> (NameNode), <code>/hadoop/dfs/data</code> (DataNode)</td>
<td>Directories used to store HDFS data, mapped to Docker volumes for persistence.</td>
</tr>
<tr>
<td><strong>Mapped Ports</strong></td>
<td>See <code>docker-compose.yml</code></td>
<td>Ports mapped between host and container for accessing Hadoop Web UIs.</td>
</tr>
<tr>
<td><strong>NameNode Web UI</strong></td>
<td><code>http://localhost:29870</code></td>
<td>Access URL for NameNode Web UI from the host machine.</td>
</tr>
<tr>
<td><strong>HDFS NameNode UI</strong></td>
<td><code>http://localhost:29070</code></td>
<td>Access URL for HDFS NameNode Web UI from the host machine.</td>
</tr>
<tr>
<td><strong>ResourceManager Web UI</strong></td>
<td><code>http://localhost:28088</code></td>
<td>Access URL for YARN ResourceManager Web UI from the host machine.</td>
</tr>
<tr>
<td><strong>NodeManager Web UI</strong></td>
<td><code>http://localhost:29864</code></td>
<td>Access URL for YARN NodeManager Web UI from the host machine.</td>
</tr>
<tr>
<td><strong>HistoryServer Web UI</strong></td>
<td><code>http://localhost:29866</code></td>
<td>Access URL for MapReduce Job HistoryServer Web UI from the host machine.</td>
</tr>
<tr>
<td><strong>HDFS Input Directory</strong></td>
<td><code>/input</code> in HDFS</td>
<td>Directory where input files for MapReduce jobs are stored in HDFS.</td>
</tr>
<tr>
<td><strong>HDFS Output Directory</strong></td>
<td><code>/output</code> in HDFS</td>
<td>Directory where output files from MapReduce jobs are stored in HDFS.</td>
</tr>
</tbody>
</table>
<h2 id="reference">Reference</h2>
<p><a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html">Official Hadoop Link</a></p>
<h1 id="create-a-single-node-hadoop-container-on-docker"><span style="color: MediumOrchid; font-family: Segoe UI, sans-serif;">Create a Single-Node Hadoop Container on Docker</span></h1>
<p>Setting up Hadoop can be quite confusing, especially if you're new to it. The best ready-to-use setups used to be provided by Cloudera, their current docker image(as on Aug 2024) has many issues. In this guide, Ill help you create a pure Hadoop container with just one node. This guide is divided into two sections: one for quick steps and another for a detailed setup. The container setup has been thoroughly tested and can be created easily.</p>
<h2 id="quick-steps-for-the-busy-people"><span style="color: #AD49B3; font-family: Segoe UI, sans-serif;">Quick Steps for the Busy People</span></h2>
<p>If youre short on time and dont want to go through the entire process of setting everything up manually, this section is for you. Just follow the instructions here, use the ready-to-use files, and your container will be up and running in a few minutes!</p>
<h3 id="steps-to-build-the-container-using-ready-to-use-files"><span style="color: #963F9C; font-family: Segoe UI, sans-serif;">Steps to build the container using ready-to-use files</span></h3>
<p style="color: #006600; font-family: 'Consolas', 'Courier New', monospace; background-color: #e6ffe6; padding: 15px; border-left: 5px solid #00cc66; font-size: 12px;">
Note: The `hadoop-3.4.0.tar.gz` file is not included in the zip because of its large size. Ive set up the Dockerfile to download this file automatically from the Apache website if its not found in the folder. However, sometimes these download links change. If you encounter any issues with the automatic download, you can manually download the `hadoop-3.4.0.tar.gz` file from <a href="https://downloads.apache.org/hadoop/common/hadoop-3.4.0/hadoop-3.4.0.tar.gz">this link</a>. If this link doesnt work, simply search online for the file, download it, and place it in the folder. You dont need to change anything in the Dockerfile; it will work as long as the file is named `hadoop-3.4.0.tar.gz`.
</p>

<p style="color: #006600; font-family: 'Consolas', 'Courier New', monospace; background-color: #ffe6e6; padding: 15px; border-left: 5px solid #cc0000; font-size: 12px;">
If you create a .sh file or any file on Windows and plan to use it in Linux, make sure you convert it to a Linux-friendly format using this <a href="https://toolslick.com/conversion/text/dos-to-unix" target="_blank">site</a>. Other methods may not work as well. It's important to convert the file, or else it might cause many unexpected errors.
</p>

<ul>
<li>Download the <a href="../Dockerfiles/hadoop-singlenode.zip">hadoop-singlenode.zip</a> file.</li>
<li>Unzip it to a folder on your laptop.</li>
<li>
<p>Open command prompt/terminal and cd to the folder where you unziped the files</p>
<p><code>bash
cd path_to_unzipped_folder</code>
- Build the doccker image from the Dockerfile. There is a <strong>dot</strong>
<code>bash
docker build -t hadoop-singlenode .</code>
- Run the container from the built image</p>
<p><code>bash
docker run -it --name hadoop-singlenode --network dasnet -p 9870:9870 -p 8088:8088 -v namenode-data:/hadoop/dfs/namenode  -v datanode-data:/hadoop/dfs/datanode -v secondarynamenode-data:/hadoop/dfs/secondarynamenode  hadoop-singlenode</code>
- From inside the running container, start the Hadoop services:</p>
<p><code>bash
sudo service ssh start
$HADOOP_HOME/sbin/start-dfs.sh
$HADOOP_HOME/sbin/start-yarn.sh</code></p>
<h3 id="check-the-setup"><span style="color: #963F9C; font-family: Segoe UI, sans-serif;">Check the setup</span></h3>
<ul>
<li>Once the services are up you can access the Hadoop links:</li>
<li>
<p><strong>HDFS NameNode Web UI:</strong> http://localhost:9870
    <img src="images/2024-08-26-01-50-36.png" alt="Description of the image" style="max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 4px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);"></p>
</li>
<li>
<p><strong>YARN ResourceManager Web UI:</strong> http://localhost:8088
    <img src="images/2024-08-26-01-50-00.png" alt="Description of the image" style="max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 4px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);"></p>
</li>
</ul>
</li>
</ul>
<h2 id="detailed-steps-building-the-setup-file-by-file"><span style="color: #AD49B3; font-family: Segoe UI, sans-serif;">Detailed steps - building the setup, file by file</span></h2>
<p>If you want to understand how to build the Docker container from scratch or make custom modifications, follow these steps.</p>
<h3 id="details-of-the-files-used"><span style="color: #963F9C; font-family: Segoe UI, sans-serif;">Details of the files used</span></h3>
<p>The setup uses 6 files, <code>Dockerfile</code>, <code>core-site.xml</code>, <code>hdfs-site.xml</code>, <code>mapred-site.xml</code>, <code>yarn-site.xml</code> and <code>hadoop-env.sh</code></p>
<ul>
<li>
<p><strong>Dockerfile:</strong> This is the main file. We only use Dockerfile for our setup and no docker-compose.yml. But, you can add a docker-compose if you need. The filename is <code>Dockerfile</code>(no extension) and has the following content:</p>
<p>```bash</p>
<h1 id="use-a-base-image-with-java-8">Use a base image with Java 8</h1>
<p>FROM openjdk:8-jdk</p>
<h1 id="set-environment-variables-for-hadoop">Set environment variables for Hadoop</h1>
<p>ENV HADOOP_VERSION=3.4.0
ENV HADOOP_HOME=/usr/local/hadoop
ENV JAVA_HOME=/usr/local/openjdk-8
ENV PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
ENV HDFS_NAMENODE_USER=dwdas
ENV HDFS_DATANODE_USER=dwdas
ENV HDFS_SECONDARYNAMENODE_USER=dwdas
ENV YARN_RESOURCEMANAGER_USER=dwdas
ENV YARN_NODEMANAGER_USER=dwdas</p>
<h1 id="install-necessary-packages">Install necessary packages</h1>
<p>RUN apt-get update &amp;&amp; \
    apt-get install -y ssh rsync sudo wget &amp;&amp; \
    apt-get clean</p>
<h1 id="set-root-password">Set root password</h1>
<p>RUN echo "root:Passw0rd" | chpasswd</p>
<h1 id="create-a-user-dwdas-with-sudo-privileges">Create a user 'dwdas' with sudo privileges</h1>
<p>RUN useradd -m -s /bin/bash dwdas &amp;&amp; \
    echo "dwdas:Passw0rd" | chpasswd &amp;&amp; \
    usermod -aG sudo dwdas &amp;&amp; \
    echo "dwdas ALL=(ALL) NOPASSWD: ALL" &gt;&gt; /etc/sudoers</p>
<h1 id="optional-download-and-extract-hadoop-tarball-if-not-already-provided">Optional: Download and extract Hadoop tarball if not already provided</h1>
<p>COPY hadoop-${HADOOP_VERSION}.tar.gz /tmp/
RUN if [ ! -f /tmp/hadoop-${HADOOP_VERSION}.tar.gz ]; then \
        wget https://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz -O /tmp/hadoop-${HADOOP_VERSION}.tar.gz; \
    fi &amp;&amp; \
    tar -xzf /tmp/hadoop-${HADOOP_VERSION}.tar.gz -C /usr/local &amp;&amp; \
    mv /usr/local/hadoop-${HADOOP_VERSION} $HADOOP_HOME &amp;&amp; \
    rm /tmp/hadoop-${HADOOP_VERSION}.tar.gz</p>
<h1 id="configure-hadoop-create-necessary-directories-on-docker-volumes">Configure Hadoop - Create necessary directories on Docker volumes</h1>
<p>RUN mkdir -p /hadoop/dfs/namenode &amp;&amp; \
    mkdir -p /hadoop/dfs/datanode &amp;&amp; \
    mkdir -p /hadoop/dfs/secondarynamenode</p>
<h1 id="copy-configuration-files">Copy configuration files</h1>
<p>COPY core-site.xml $HADOOP_HOME/etc/hadoop/
COPY hdfs-site.xml $HADOOP_HOME/etc/hadoop/
COPY mapred-site.xml $HADOOP_HOME/etc/hadoop/
COPY yarn-site.xml $HADOOP_HOME/etc/hadoop/</p>
<h1 id="copy-and-configure-hadoop-envsh-java_home-must-be-set-here-also">Copy and configure hadoop-env.sh. JAVA_HOME MUST be set here also.</h1>
<p>COPY hadoop-env.sh $HADOOP_HOME/etc/hadoop/hadoop-env.sh</p>
<h1 id="set-ownership-for-hadoop-directories-and-volumes-to-dwdas">Set ownership for Hadoop directories and volumes to 'dwdas'</h1>
<p>RUN chown -R dwdas:dwdas $HADOOP_HOME /hadoop/dfs/namenode /hadoop/dfs/datanode /hadoop/dfs/secondarynamenode</p>
<h1 id="switch-to-the-dwdas-user-for-all-subsequent-operations">Switch to the dwdas user for all subsequent operations</h1>
<p>USER dwdas</p>
<h1 id="create-the-ssh-directory-and-set-permissions">Create the .ssh directory and set permissions</h1>
<p>RUN mkdir -p /home/dwdas/.ssh &amp;&amp; \
    chmod 700 /home/dwdas/.ssh</p>
<h1 id="generate-ssh-keys-for-passwordless-ssh-login-and-configure-ssh">Generate SSH keys for passwordless SSH login and configure SSH</h1>
<p>RUN ssh-keygen -t rsa -P '' -f /home/dwdas/.ssh/id_rsa &amp;&amp; \
    cat /home/dwdas/.ssh/id_rsa.pub &gt;&gt; /home/dwdas/.ssh/authorized_keys &amp;&amp; \
    chmod 600 /home/dwdas/.ssh/authorized_keys &amp;&amp; \
    echo "Host localhost" &gt;&gt; /home/dwdas/.ssh/config &amp;&amp; \
    echo "   StrictHostKeyChecking no" &gt;&gt; /home/dwdas/.ssh/config &amp;&amp; \
    chmod 600 /home/dwdas/.ssh/config</p>
<h1 id="format-hdfs-as-dwdas-user">Format HDFS as 'dwdas' user</h1>
<p>RUN $HADOOP_HOME/bin/hdfs namenode -format</p>
<h1 id="expose-the-necessary-ports-for-hadoop-services">Expose the necessary ports for Hadoop services</h1>
<p>EXPOSE 9870 8088 19888</p>
<h1 id="set-the-container-to-start-in-the-dwdas-users-home-directory">Set the container to start in the dwdas user's home directory</h1>
<p>WORKDIR /home/dwdas</p>
<h1 id="set-the-container-to-start-with-a-bash-shell">Set the container to start with a bash shell</h1>
<p>CMD ["bash"]</p>
<p><code>- **core-site.xml**: Configures the default filesystem and permissions.</code>xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
    <property>
        <name>dfs.permissions</name>
        <value>false</value>
    </property>
</configuration>
```</p>
</li>
<li>
<p><strong>hdfs-site.xml</strong>: Configures the NameNode and DataNode directories.
    <code>xml
    &lt;configuration&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
            &lt;value&gt;file:///usr/local/hadoop/tmp/hdfs/namenode&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
            &lt;value&gt;file:///usr/local/hadoop/tmp/hdfs/datanode&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.replication&lt;/name&gt;
            &lt;value&gt;1&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.permissions.superusergroup&lt;/name&gt;
            &lt;value&gt;dwdas&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.cluster.administrators&lt;/name&gt;
            &lt;value&gt;dwdas&lt;/value&gt;
        &lt;/property&gt;
    &lt;/configuration&gt;</code></p>
</li>
<li>
<p><strong>mapred-site.xml</strong>: Configures the MapReduce framework to use YARN.
    <code>xml
    &lt;configuration&gt;
        &lt;property&gt;
            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
            &lt;value&gt;yarn&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;mapred.job.tracker&lt;/name&gt;
            &lt;value&gt;hadoop-master:9001&lt;/value&gt;
        &lt;/property&gt;
    &lt;/configuration&gt;</code></p>
</li>
<li>
<p><strong>yarn-site.xml</strong>: Configures YARN services.
    <code>xml
    &lt;configuration&gt;
        &lt;property&gt;
            &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
            &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
        &lt;/property&gt;
    &lt;/configuration&gt;</code></p>
</li>
<li>
<p><strong>hadoop-env.sh:</strong> I havent included this entire file because its large, and theres only <strong>one change</strong> you need to make. Refer to the <code>hadoop-env.sh</code> file in the zip folder. The only modification required is shown below. Note: This step is crucial. Without this, Hadoop will give an error saying it cant find <code>JAVA_HOME</code>, even if youve already set it as an environment variable. This change follows Apache's instructions.</p>
<p><code>bash
export JAVA_HOME=/usr/local/openjdk-8</code></p>
</li>
</ul>
<h3 id="building-running-and-testing-the-setup"><span style="color: #963F9C; font-family: Segoe UI, sans-serif;">Building, Running, and Testing the Setup</span></h3>
<p>The process for building, running, and testing the setup is the same as described in the <a href="#quick-steps-for-the-busy-people">Quick Steps section</a>. Simply navigate to the folder, build the container, and then run it as before.</p>
<h3 id="how-to-test-the-setup"><span style="color: #963F9C; font-family: Segoe UI, sans-serif;">How to test the setup?</span></h3>
<p>The table below shows how various components and functionalities could be tested:</p>
<table>
<thead>
<tr>
<th><strong>Category</strong></th>
<th><strong>Action</strong></th>
<th><strong>Command/URL</strong></th>
<th><strong>What to Look For</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Verify HDFS</strong></td>
<td>Check HDFS status</td>
<td><code>hdfs dfsadmin -report</code></td>
<td>A detailed report on the HDFS cluster, showing live nodes, configured capacity, used space, etc.</td>
</tr>
<tr>
<td></td>
<td>Browse HDFS NameNode Web UI</td>
<td><code>http://localhost:9870</code></td>
<td>The HDFS NameNode web interface should load, showing the health of the file system.</td>
</tr>
<tr>
<td></td>
<td>Create a directory</td>
<td><code>hdfs dfs -mkdir /test</code></td>
<td>No errors, and the directory <code>/test</code> should be created successfully in HDFS.</td>
</tr>
<tr>
<td></td>
<td>List directory contents</td>
<td><code>hdfs dfs -ls /</code></td>
<td>The newly created <code>/test</code> directory should be listed.</td>
</tr>
<tr>
<td><strong>Verify YARN</strong></td>
<td>Check YARN NodeManager status</td>
<td><code>yarn node -list</code></td>
<td>A list of nodes managed by YARN, showing their status (e.g., healthy, active).</td>
</tr>
<tr>
<td></td>
<td>Browse YARN ResourceManager Web UI</td>
<td><code>http://localhost:8088</code></td>
<td>The YARN ResourceManager web interface should load, showing job and node statuses.</td>
</tr>
<tr>
<td><strong>Verify Hadoop Services</strong></td>
<td>Check running services</td>
<td><code>jps</code></td>
<td>List of Java processes such as <code>NameNode</code>, <code>DataNode</code>, <code>ResourceManager</code>, and <code>NodeManager</code>.</td>
</tr>
<tr>
<td><strong>Test MapReduce</strong></td>
<td>Run a test MapReduce job</td>
<td><code>hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar wordcount /test /output</code></td>
<td>The MapReduce job should complete successfully, creating an output directory in HDFS.</td>
</tr>
<tr>
<td></td>
<td>Verify MapReduce output</td>
<td><code>hdfs dfs -ls /output</code></td>
<td>The <code>/output</code> directory should contain the results of the MapReduce job.</td>
</tr>
</tbody>
</table>
<h3 id="setup-details"><span style="color: #963F9C; font-family: Segoe UI, sans-serif;">Setup details</span></h3>
<table>
<thead>
<tr>
<th><strong>Component</strong></th>
<th><strong>Item</strong></th>
<th><strong>Location/Value</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Hadoop Installation</strong></td>
<td><strong>Directory</strong></td>
<td><code>/usr/local/hadoop</code></td>
<td>Hadoop installation directory.</td>
</tr>
<tr>
<td></td>
<td><strong>Version</strong></td>
<td><code>3.4.0</code></td>
<td>Hadoop version.</td>
</tr>
<tr>
<td></td>
<td><strong>Core Config</strong></td>
<td><code>$HADOOP_HOME/etc/hadoop/core-site.xml</code></td>
<td>Core configuration file.</td>
</tr>
<tr>
<td></td>
<td><strong>HDFS Config</strong></td>
<td><code>$HADOOP_HOME/etc/hadoop/hdfs-site.xml</code></td>
<td>HDFS configuration file.</td>
</tr>
<tr>
<td></td>
<td><strong>MapReduce Config</strong></td>
<td><code>$HADOOP_HOME/etc/hadoop/mapred-site.xml</code></td>
<td>MapReduce configuration file.</td>
</tr>
<tr>
<td></td>
<td><strong>YARN Config</strong></td>
<td><code>$HADOOP_HOME/etc/hadoop/yarn-site.xml</code></td>
<td>YARN configuration file.</td>
</tr>
<tr>
<td></td>
<td><strong>Env Variables</strong></td>
<td><code>$HADOOP_HOME/etc/hadoop/hadoop-env.sh</code></td>
<td>Hadoop environment variables.</td>
</tr>
<tr>
<td><strong>HDFS Directories</strong></td>
<td><strong>NameNode</strong></td>
<td><code>/hadoop/dfs/namenode</code></td>
<td>HDFS NameNode data directory (Docker volume).</td>
</tr>
<tr>
<td></td>
<td><strong>DataNode</strong></td>
<td><code>/hadoop/dfs/datanode</code></td>
<td>HDFS DataNode data directory (Docker volume).</td>
</tr>
<tr>
<td></td>
<td><strong>Secondary NameNode</strong></td>
<td><code>/hadoop/dfs/secondarynamenode</code></td>
<td>Secondary NameNode directory (Docker volume).</td>
</tr>
<tr>
<td><strong>Environment Variables</strong></td>
<td><strong>Hadoop Home</strong></td>
<td><code>/usr/local/hadoop</code></td>
<td>Path to Hadoop installation.</td>
</tr>
<tr>
<td></td>
<td><strong>Java Home</strong></td>
<td><code>/usr/local/openjdk-8</code></td>
<td>Path to Java installation.</td>
</tr>
<tr>
<td></td>
<td><strong>System Path</strong></td>
<td><code>$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</code></td>
<td>Updated path including Hadoop binaries.</td>
</tr>
<tr>
<td></td>
<td><strong>HDFS_NAMENODE_USER</strong></td>
<td><code>dwdas</code></td>
<td>User for NameNode service.</td>
</tr>
<tr>
<td></td>
<td><strong>HDFS_DATANODE_USER</strong></td>
<td><code>dwdas</code></td>
<td>User for DataNode service.</td>
</tr>
<tr>
<td></td>
<td><strong>HDFS_SECONDARYNAMENODE_USER</strong></td>
<td><code>dwdas</code></td>
<td>User for Secondary NameNode service.</td>
</tr>
<tr>
<td></td>
<td><strong>YARN_RESOURCEMANAGER_USER</strong></td>
<td><code>dwdas</code></td>
<td>User for ResourceManager service.</td>
</tr>
<tr>
<td></td>
<td><strong>YARN_NODEMANAGER_USER</strong></td>
<td><code>dwdas</code></td>
<td>User for NodeManager service.</td>
</tr>
<tr>
<td><strong>Networking</strong></td>
<td><strong>Docker Network</strong></td>
<td><code>dasnet</code></td>
<td>Docker network for the Hadoop container.</td>
</tr>
<tr>
<td><strong>Ports Mapped</strong></td>
<td><strong>HDFS NameNode UI</strong></td>
<td><code>9870:9870</code></td>
<td>Port mapping for HDFS NameNode web interface.</td>
</tr>
<tr>
<td></td>
<td><strong>YARN ResourceManager UI</strong></td>
<td><code>8088:8088</code></td>
<td>Port mapping for YARN ResourceManager web interface.</td>
</tr>
</tbody>
</table>
<h2 id="appendix"><span style="color: #AD49B3; font-family: Segoe UI, sans-serif;">Appendix</span></h2>
<ul>
<li><strong>Alternate command - Start the Namenode</strong>
    <code>sh
    $HADOOP_HOME/sbin/hadoop-daemon.sh start namenode</code></li>
<li>
<p><strong>Alternate command - Start the Datanode</strong>
    <code>sh
    $HADOOP_HOME/sbin/hadoop-daemon.sh start datanode</code></p>
</li>
<li>
<p><strong>Enter <code>jps</code> to see all the hadoop services</strong></p>
<p><img src="images/2024-08-24-02-51-36.png" alt="Description of the image" style="max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 4px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);"></p>
</li>
<li>
<p><strong>Command to get a report on the Hadoop setup</strong></p>
<p><code>sh
hdfs dfsadmin -report</code>
<img src="images/2024-08-24-02-56-50.png" alt="Description of the image" style="max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 4px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);"></p>
</li>
</ul>
<h2 id="common-errors-and-their-solutions"><span style="color: #AD49B3; font-family: Segoe UI, sans-serif;">Common Errors and Their Solutions</span></h2>
<ul>
<li><strong>Port Binding Error</strong>:</li>
<li><strong>Error</strong>: <code>Ports are not available: exposing port TCP 0.0.0.0:50070 -&gt; 0.0.0.0:0: listen tcp 0.0.0.0:50070: bind: An attempt was made to access a socket in a way forbidden by its access permissions.</code></li>
<li>
<p><strong>Solution</strong>: Make sure that the ports youre using arent already in use by other services. You can check and stop any process using these ports with these commands:
     <code>sh
     netstat -aon | findstr :50070
     taskkill /PID &lt;PID&gt; /F</code>
     Or you can change the port numbers in the Dockerfile and <code>docker run</code> command.</p>
</li>
<li>
<p><strong>Permission Denied Error</strong>:</p>
</li>
<li><strong>Error</strong>: <code>ERROR: Attempting to operate on hdfs namenode as root but there is no HDFS_NAMENODE_USER defined.</code></li>
<li>
<p><strong>Solution</strong>: Hadoop services should not run as the root user. The Dockerfile sets up a non-root user (<code>dwdas</code>) to run Hadoop and Hive services:
     <code>Dockerfile
     ENV HDFS_NAMENODE_USER=dwdas
     ENV HDFS_DATANODE_USER=dwdas
     ENV HDFS_SECONDARYNAMENODE_USER=dwdas
     ENV YARN_RESOURCEMANAGER_USER=dwdas
     ENV YARN_NODEMANAGER_USER=dwdas</code></p>
</li>
<li>
<p><strong>Multiple SLF4J Bindings Error</strong>:</p>
</li>
<li><strong>Error</strong>: <code>SLF4J: Class path contains multiple SLF4J bindings.</code></li>
<li><strong>Solution</strong>: This is usually just a warning, not an error. It means there are multiple SLF4J bindings in the classpath. It can generally be ignored, but if it causes issues, you might need to clean up the classpath by removing conflicting SLF4J jars.</li>
</ul></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../../../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../js/base.js"></script>
        <script src="../../../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
