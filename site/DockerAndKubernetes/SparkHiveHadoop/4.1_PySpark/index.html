<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../../img/favicon.ico">
        <title>PySpark - My Docs</title>
        <link href="../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../css/fontawesome.min.css" rel="stylesheet">
        <link href="../../../css/brands.min.css" rel="stylesheet">
        <link href="../../../css/solid.min.css" rel="stylesheet">
        <link href="../../../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../../../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../../..">My Docs</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="nav-item">
                                <a href="../../.." class="nav-link">Welcome to MkDocs</a>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Airflow</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../Airflow/1.0.0_AirFlow_Concepts/" class="dropdown-item">Airflow Concepts</a>
</li>
                                    
<li>
    <a href="../../../Airflow/1.0.1_A_Dags_Anatomy/" class="dropdown-item">A dags anatomy</a>
</li>
                                    
<li>
    <a href="../../../Airflow/1.0.2_Hello_Airflow/" class="dropdown-item">Hello-Airflow</a>
</li>
                                    
<li>
    <a href="../../../Airflow/1.0.3_Airflow_Dbt_Docker/" class="dropdown-item">Project Airflow dbt</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">DE Projects</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../DE-Projects/Csv-To-MSSQL/" class="dropdown-item">Python - CSV To MSSQL</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/CurrencyPredictor/" class="dropdown-item">CurrencyPredictor</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Dbrk-E2E-AttritionProject/" class="dropdown-item">Problem Statement</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Download-Haddop-Jars/" class="dropdown-item">Download JARs-Apache Maven Repo</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/FetchJsonWriteParquet/" class="dropdown-item">Json To Parquet Using Spark And Azure</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/InstallScala/" class="dropdown-item">Scala Install</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/JsonFlatAzureSDK/" class="dropdown-item">Flatten Json Using Azure SDK</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/LocalPython_AzureBlob/" class="dropdown-item">Local Python Code to Rearrange Files in a Azure Blob Container</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Microsoft_OpenJDK/" class="dropdown-item">Microsoft OpenJDK</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Project_MigrationToAzureBlob/" class="dropdown-item">CMS Migration to Azure Blob</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Project_MongoCMS/" class="dropdown-item">CMS using MongoDB</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Project_SSRS_SSIS_SharePoint/" class="dropdown-item">Project - ETL and Reporting Lending Org</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/Raw-Json-To-Hive/" class="dropdown-item">Raw Json To Hive</a>
</li>
                                    
<li>
    <a href="../../../DE-Projects/SPY_ETF_Buy_Recommender/" class="dropdown-item">SPY ETF Buy Recommender</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">AzureSkyWeather</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/AzureSkyWeather/HomeProjectAzureSkyWeather/" class="dropdown-item">Project AzureSkyWeather</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">1 Ingestion</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">HttpTriggered</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/AzureSkyWeather/1_Ingestion/HttpTriggered/HTTPTriggered_AzureFunc/" class="dropdown-item">Part 1A - Using Azure HTTP-Triggered Function</a>
</li>
            
<li>
    <a href="../../../DE-Projects/AzureSkyWeather/1_Ingestion/HttpTriggered/nav2_AzureFunctions/" class="dropdown-item">Azure Functions Quickstart</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">TimerTriggered</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/AzureSkyWeather/1_Ingestion/TimerTriggered/TimerTriggered_AzureFunc/" class="dropdown-item">Part 1B - Using Azure Timer-Triggered Function</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">2 Transformation</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/AzureSkyWeather/2_Transformation/Solution_Details/" class="dropdown-item">Solution Details</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">JsonValidator</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/JsonValidator/AzureFunction-ValidateJSOns/" class="dropdown-item">Azure Functions - Validate JSONs</a>
</li>
            
<li>
    <a href="../../../DE-Projects/JsonValidator/Python-ValidateJSONs/" class="dropdown-item">Validate JSON using Python</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Sparkzure</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/Sparkzure/HomeProjectSparkzure/" class="dropdown-item">Project Sparkzure</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">StreamKraft</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DE-Projects/StreamKraft/HomeProjectStreamKraft/" class="dropdown-item">Project StreamKraft</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">DevOps</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../DevOps/1.1_Hello_GitHub_Actions_Workflow/" class="dropdown-item">Hello GitHub Actions Workflow</a>
</li>
                                    
<li>
    <a href="../../../DevOps/1.1_Sample_Workflows/" class="dropdown-item">Sample Workflows</a>
</li>
                                    
<li>
    <a href="../../../DevOps/1_GitHub-Concepts/" class="dropdown-item">GitHub Concepts</a>
</li>
                                    
<li>
    <a href="../../../DevOps/2.1_Self-Hosted_Agent_Windows/" class="dropdown-item">Self-Hosted-Agent-Windows</a>
</li>
                                    
<li>
    <a href="../../../DevOps/2.2_Self-Hosted_Agent_Windows_Container/" class="dropdown-item">Self-Hosted-Agent-Win-Container</a>
</li>
                                    
<li>
    <a href="../../../DevOps/2.3_Self-Hosted_Agent_Linux_Container/" class="dropdown-item">Self-Hosted-Agent-Ubuntu-Container</a>
</li>
                                    
<li>
    <a href="../../../DevOps/2_Azure-Pipelines/" class="dropdown-item">Azure-Pipelines</a>
</li>
                                    
<li>
    <a href="../../../DevOps/ADF_CICD/" class="dropdown-item">ADF-CI-CD</a>
</li>
                                    
<li>
    <a href="../../../DevOps/Biceps/" class="dropdown-item">What is Bicep?</a>
</li>
                                    
<li>
    <a href="../../../DevOps/CI-CD_in%20ADF/" class="dropdown-item">CI CD in ADF</a>
</li>
                                    
<li>
    <a href="../../../DevOps/GitScenarios/" class="dropdown-item">GitScenarios</a>
</li>
                                    
<li>
    <a href="../../../DevOps/JenkinsVsGitHubVsAzureDevOps/" class="dropdown-item">Jenkins Vs GitHub Vs Devops</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle active" aria-current="page" role="button" data-bs-toggle="dropdown"  aria-expanded="false">DockerAndKubernetes</a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">AirflowDocker</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../AirflowDocker/1_AirflowDocker/" class="dropdown-item">Airflow</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Kafka</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../Kafka/2_Confluent%20Kafka/" class="dropdown-item">Confluent Kafka</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Mongodb</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../Mongodb/3_DockerMongodb/" class="dropdown-item">MongoDB</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">SparkHiveHadoop</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="./" class="dropdown-item active" aria-current="page">PySpark</a>
</li>
            
<li>
    <a href="../4.2_Bitnami_Spark_Cluster/" class="dropdown-item">Bitnami Spark</a>
</li>
            
<li>
    <a href="../4.3_VSCode_Docker_Connection/" class="dropdown-item">VSCode-Docker-Connection</a>
</li>
            
<li>
    <a href="../4.4_Spark_Hive_MSSQL/" class="dropdown-item">Spark-Hive_MSSQL</a>
</li>
            
<li>
    <a href="../4.5_Hadoop_Cluster_Single_N_MultiNode/" class="dropdown-item">Hadoop Cluster</a>
</li>
            
<li>
    <a href="../4.6_Hive_Hadooop_Postgres_Presto/" class="dropdown-item">bde2020-Hive-Hadoop-Presto</a>
</li>
            
<li>
    <a href="../4.7_Hadoop_Hive_SingleNode_MySQL/" class="dropdown-item">Hive-Hadoop-MySQL-SingleNode</a>
</li>
            
<li>
    <a href="../4.8_Hive-ApacheOfficial/" class="dropdown-item">Hive Official Setup</a>
</li>
            
<li>
    <a href="../4.9.1_Hive_Concepts/" class="dropdown-item">Hive Concepts</a>
</li>
            
<li>
    <a href="../4.9.2_Hadoop_Concepts/" class="dropdown-item">Hadoop Concepts</a>
</li>
            
<li>
    <a href="../4.9_DockerConcepts/" class="dropdown-item">Docker Misc Concepts</a>
</li>
            
<li>
    <a href="../4_Spark-Hive-Hadoop/" class="dropdown-item">4 Spark Hive Hadoop</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">M365</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../M365/DocumentumToSharePoint/" class="dropdown-item">Documentum-SharePoint Online</a>
</li>
                                    
<li>
    <a href="../../../M365/LicensingExamples/" class="dropdown-item">M365 Licensing Examples</a>
</li>
                                    
<li>
    <a href="../../../M365/SPMT/" class="dropdown-item">SPMT - SharePoint Migration</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePoint2007FarmUpgrade/" class="dropdown-item">SharePoint Farm Upgrade</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePoint2016FarmUpgrade/" class="dropdown-item">SharePoint Farm 2016 Farm Setup</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePointEvents/" class="dropdown-item">SharePoint Event Receiver</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePointFarmConsolidation/" class="dropdown-item">SharePoint Farm Consolidation</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePointFormsOrPowerApps/" class="dropdown-item">SharePoint Forms or PowerApps</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePointMiniRole/" class="dropdown-item">SharePoint Mini Role</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePointVersionEvolution/" class="dropdown-item">SharePoint Evolution</a>
</li>
                                    
<li>
    <a href="../../../M365/SharePointVsOtherECM/" class="dropdown-item">SharePoint vs Other ECMS</a>
</li>
                                    
<li>
    <a href="../../../M365/WSS3DocumentUpload/" class="dropdown-item">Project - C# - WSS 3 Bulk ingestion</a>
</li>
                                    
<li>
    <a href="../../../M365/oAuthSharePointPython/" class="dropdown-item">Python-oAuth-SharePointOnline</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Microsoft Fabric</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../Microsoft-Fabric/DataFactory/" class="dropdown-item">Pipelines&DataFlows</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/DataScience/" class="dropdown-item">Data Science on Fabric Overview</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/DataWareHouse/" class="dropdown-item">DataWareHouse</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/DirectLake/" class="dropdown-item">DirectLake|Fabric|PowerBI</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/E2EProject/" class="dropdown-item">E2EProject</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/ETL-OPG-Copydata-JSON-Lakehouse/" class="dropdown-item">JSON-DeltaLake-OPG</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/ETL-Pyspark-Notebook-Lakehouse/" class="dropdown-item">ETL-Load data into Lakehouse - Pyspark Notebook</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/FabricAdministration/" class="dropdown-item">Administration</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/FabricQ%26A/" class="dropdown-item">Fabric Q&A</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/FabricSparkStreaming/" class="dropdown-item">Spark Streaming</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/HelloMicrosoftFabric/" class="dropdown-item">Hello Fabric</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/InspectingDataframes/" class="dropdown-item">Whats in your df?</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/KQL/" class="dropdown-item">KQL</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/PandasVsSparkDf/" class="dropdown-item">PandasVsSparkDf</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/Pyspark_SparkSQL/" class="dropdown-item">Pyspark|SparkSQL CheatSheet</a>
</li>
                                    
<li>
    <a href="../../../Microsoft-Fabric/RealTimeAnalytics/" class="dropdown-item">Real-time Intelligence</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Misc</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../Misc/10_Fact_vs_Dimension_tables/" class="dropdown-item">Fact Vs Dimension Table</a>
</li>
                                    
<li>
    <a href="../../../Misc/1_GoogleCloudSeeUsage/" class="dropdown-item">Check Google Usage</a>
</li>
                                    
<li>
    <a href="../../../Misc/2_InstallVMWareFree/" class="dropdown-item">VMWare For Free</a>
</li>
                                    
<li>
    <a href="../../../Misc/3_Markdown/" class="dropdown-item">Markdown</a>
</li>
                                    
<li>
    <a href="../../../Misc/4_VSTrics/" class="dropdown-item">Visual Studio Code Tricks</a>
</li>
                                    
<li>
    <a href="../../../Misc/5_WhichDatastsToUse/" class="dropdown-item">Free Datasets for Data Practice</a>
</li>
                                    
<li>
    <a href="../../../Misc/6_RunningAppsInBg/" class="dropdown-item">Running Service in Background</a>
</li>
                                    
<li>
    <a href="../../../Misc/7_Azure_Budget/" class="dropdown-item">How to set a Azure Budget</a>
</li>
                                    
<li>
    <a href="../../../Misc/9_WhyUbuntuIsGood/" class="dropdown-item">Why Ubuntu is good to learn</a>
</li>
                                    
<li>
    <a href="../../../Misc/markdown_pdf_export_html/" class="dropdown-item">Markdown pdf export html</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">MarkdownColor.md</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Misc/MarkdownColor.md/Color/" class="dropdown-item">Color Reference</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Images</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Misc/MarkdownColor.md/images/Color/" class="dropdown-item">Color Palettes</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">MongoDB</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../MongoDB/HowMongoDBStoresFiles/" class="dropdown-item">How MongoDB Stores Data</a>
</li>
                                    
<li>
    <a href="../../../MongoDB/MongbDB_Vs_Atlas_VsCosmosDB/" class="dropdown-item">MongoDB Vs CosmosDB</a>
</li>
                                    
<li>
    <a href="../../../MongoDB/MongoDBCommands/" class="dropdown-item">MongoDB Commands</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">PowerPlatform</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../PowerPlatform/CalculationGroups/" class="dropdown-item">CalculationGroups</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/CustomConnectors/" class="dropdown-item">Building Custom Connectors</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/ECMCaptureFlow/" class="dropdown-item">Power Automate Or Kofax/Captiva?</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/EnableMicrosoftSyntex/" class="dropdown-item">Enable Microsoft Syntex on your Office 365 tenant</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/EnableSyntexOnYourDocumentLibrary/" class="dropdown-item">Create a model on SharePoint - Syntex</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/GoogleProviderPowerPages/" class="dropdown-item">Google Authentication</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/HealthClinicDataverseSecurity/" class="dropdown-item">HealthClinicDataverseSecurity</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/HelloDataverse/" class="dropdown-item">Hello Dataverse</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/HelloDynamics365/" class="dropdown-item">Dynamics 365 Ecosystem</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/HelloPowerPlatform/" class="dropdown-item">PowerPlatform Ecosystem</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/ModelDrivenApps/" class="dropdown-item">Model-Driven Apps</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/OnPremiseGateway/" class="dropdown-item">Onpremise Gateway</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/PowerAutomateIsWorkflowTeams/" class="dropdown-item">Workflow is Power Automate</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/PowerPlatformAdminCentral/" class="dropdown-item">PowerPlatformAdminCentral</a>
</li>
                                    
<li>
    <a href="../../../PowerPlatform/PowerPlatformQ%26A/" class="dropdown-item">Pl-900-Q&A</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">DocumentIntelligence</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../PowerPlatform/DocumentIntelligence/AAIDI_AzureCognitiveSearch/" class="dropdown-item">Integrate AI Search and Azure AI Document Intelligence</a>
</li>
            
<li>
    <a href="../../../PowerPlatform/DocumentIntelligence/AAIDI_Q%26A/" class="dropdown-item">AAIDI Q&A</a>
</li>
            
<li>
    <a href="../../../PowerPlatform/DocumentIntelligence/AzureAIDocumentIntelligence/" class="dropdown-item">Azure AI Document Intelligence</a>
</li>
            
<li>
    <a href="../../../PowerPlatform/DocumentIntelligence/DocumentAutomation/" class="dropdown-item">Document automation base kit</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Python</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../Python/1.0_Sets/" class="dropdown-item">Sets</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.0_assert_methods/" class="dropdown-item">assert methods</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.1_decorators/" class="dropdown-item">decorators</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.2_argv/" class="dropdown-item">argv</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.3_Diff_And_Patch/" class="dropdown-item">diffAndpatch</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.3_error_handling/" class="dropdown-item">Error Handling</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.4_pdb/" class="dropdown-item">pdb</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1.5_pyformat/" class="dropdown-item">format method</a>
</li>
                                    
<li>
    <a href="../../../Python/1.10_Func_Modl_Summary/" class="dropdown-item">LFM Summary</a>
</li>
                                    
<li>
    <a href="../../../Python/1.11_ifelifelse/" class="dropdown-item">ifelifelse</a>
</li>
                                    
<li>
    <a href="../../../Python/1.12_Operators/" class="dropdown-item">operators</a>
</li>
                                    
<li>
    <a href="../../../Python/1.13_For_Loops/" class="dropdown-item">for loops</a>
</li>
                                    
<li>
    <a href="../../../Python/1.14_enumerate/" class="dropdown-item">1.14 enumerate</a>
</li>
                                    
<li>
    <a href="../../../Python/1.15_range_function/" class="dropdown-item">range function</a>
</li>
                                    
<li>
    <a href="../../../Python/1.16_built_in_functions/" class="dropdown-item">1.16 built in functions</a>
</li>
                                    
<li>
    <a href="../../../Python/1.17_withStatement/" class="dropdown-item">with statement</a>
</li>
                                    
<li>
    <a href="../../../Python/1.18_unittest_pytest/" class="dropdown-item">pytest</a>
</li>
                                    
<li>
    <a href="../../../Python/1.19_if_name_main.md/" class="dropdown-item">if__name__main</a>
</li>
                                    
<li>
    <a href="../../../Python/1.1_Tuples/" class="dropdown-item">Tuples</a>
</li>
                                    
<li>
    <a href="../../../Python/1.2_Tuples_Advanced/" class="dropdown-item">Advanced Tuples</a>
</li>
                                    
<li>
    <a href="../../../Python/1.3_List/" class="dropdown-item">1.3 List</a>
</li>
                                    
<li>
    <a href="../../../Python/1.4_Dictionaries/" class="dropdown-item">1.4 Dictionaries</a>
</li>
                                    
<li>
    <a href="../../../Python/1.5_Lamda_Functions/" class="dropdown-item">Lamda Functions</a>
</li>
                                    
<li>
    <a href="../../../Python/1.9_Func_Modl_Lib/" class="dropdown-item">Library-Modules-Funcs</a>
</li>
                                    
<li>
    <a href="../../../Python/1_Python/" class="dropdown-item">Python</a>
</li>
                                    
<li>
    <a href="../../../Python/Linux/" class="dropdown-item">Essential Unix Commands</a>
</li>
                                    
<li>
    <a href="../../../Python/Pyspark/" class="dropdown-item">PySpark</a>
</li>
                                    
<li>
    <a href="../../../Python/PythonScripts/" class="dropdown-item">Python Sample Scripts</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">GraphAPIJupyter</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Python/GraphAPIJupyter/GraphAPIUsingJuputer/" class="dropdown-item">Graph API - Juputer</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">SQL</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../SQL/1.0.0_dbt/" class="dropdown-item">dbt</a>
</li>
                                    
<li>
    <a href="../../../SQL/1.0.1_setup_simple_dbt_project/" class="dropdown-item">1.0.1 setup simple dbt project</a>
</li>
                                    
<li>
    <a href="../../../SQL/FlatFileSoure/" class="dropdown-item">FlatFileSoure</a>
</li>
                                    
<li>
    <a href="../../../SQL/InputAndOutputProperties/" class="dropdown-item">Understanding External Columns and Output Columns in SSIS</a>
</li>
                                    
<li>
    <a href="../../../SQL/MSSQL_Versions/" class="dropdown-item">SQL Server Versions</a>
</li>
                                    
<li>
    <a href="../../../SQL/Project_1-ETL-CSV-MSSQL/" class="dropdown-item">Project 1 - ETL Flat Files to MSSQL</a>
</li>
                                    
<li>
    <a href="../../../SQL/Project_2-UsingWebServicesInSSIS/" class="dropdown-item">Project 2 - Web Service SSIS Script Task</a>
</li>
                                    
<li>
    <a href="../../../SQL/SQL/" class="dropdown-item">Spark-SQL</a>
</li>
                                    
<li>
    <a href="../../../SQL/SQL_AdvancedTopics/" class="dropdown-item">SQL Advanced Topics</a>
</li>
                                    
<li>
    <a href="../../../SQL/SSIS/" class="dropdown-item">SQL Server Integration Services</a>
</li>
                                    
<li>
    <a href="../../../SQL/SSRS/" class="dropdown-item">SSRS</a>
</li>
                                    
<li>
    <a href="../../../SQL/Windows_Functions/" class="dropdown-item">Window Functions</a>
</li>
                                    
<li>
    <a href="../../../SQL/connecting-with-dbt/" class="dropdown-item">Connect Local dbt with MSSQL Server</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Spark DataBricks</a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">1.0 Spark</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.0_Spark-Concepts/" class="dropdown-item">Spark</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.10_Scala_Cheatsheet/" class="dropdown-item">Scala Cheatsheet</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.11_Spark_Interview_Questions/" class="dropdown-item">Spark Interview Questions</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.12_Spark_Shuffle/" class="dropdown-item">Shuffle in Spark</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.13_SparkDatabaseTablesCatalogsMetastore/" class="dropdown-item">Spark DB-Tables-Metastore-Catalogs</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.14_Q%26A/" class="dropdown-item">Q&A</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.15_CommonPysparkTopics/" class="dropdown-item">PySpark Concepts I</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.16_ConnectingSparkToHive/" class="dropdown-item">Spark-Hive-Delta Connection</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.1_NarrowVsWideTransformation/" class="dropdown-item">Narrow_Vs_Wide_Transformation</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.2_SparkArchitecture/" class="dropdown-item">Spark Architecture</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.3_persist_and_cache/" class="dropdown-item">persist and cache</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.4_broadcastvariables/" class="dropdown-item">Broadcast Variables</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.5_DataSkewHandling/" class="dropdown-item">Data Skew in Spark</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.6_dropna_fillna_df_missing_val_handling/" class="dropdown-item">dropna and fillna</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.7_distinct_dropDuplicate_windowsFunc/" class="dropdown-item">Removing Duplicates - PySpark</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.8_Partition_Grouping/" class="dropdown-item">Partition And Bucket</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/1.9_RDD_Dataframe_Dataset/" class="dropdown-item">RDD-Dataframe-Dataset</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Install Pyspark Windows</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Spark-DataBricks/1.0_Spark/Install-Pyspark-Windows/Install-Pyspark-Windows/" class="dropdown-item">Install-PySpark-Windows</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">2.0 Spark To ADLS</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Spark-DataBricks/2.0_Spark_To_ADLS/2.0_Spark_To_ADLS/" class="dropdown-item">Spark-To-ADLS-Connection</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/2.0_Spark_To_ADLS/2.1_Spark-To_ADLS_Summary/" class="dropdown-item">Spark-To-ADLS-Summary</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">3.0 Databricks</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.0_Databricks_Concepts/" class="dropdown-item">Databricks</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.1_Catalogs_And_Metastore/" class="dropdown-item">Hive Metastore and the hive_metastore folder</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.2_AuthenticationMethods/" class="dropdown-item">Authentication Method</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.3_Mount_ADLS_on_Databricks/" class="dropdown-item">Mount ADLS on Databricks</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.4_Databricks_Secret_Scope/" class="dropdown-item">Secret Scope</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.5_Databricks_SQL/" class="dropdown-item">CREATE TABLE USING</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.6_DatabricksMagicCommands/" class="dropdown-item">Magic Commands</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/3.7_DeltaLake_And_Lakehouse/" class="dropdown-item">Delta Lake And Lakehouse</a>
</li>
            
<li>
    <a href="../../../Spark-DataBricks/3.0_Databricks/4.8_Databricks_ProjectA1/" class="dropdown-item">Project-A</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">4.0 Hive</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Spark-DataBricks/4.0_Hive/Hive_Concepts/" class="dropdown-item">Hive Concepts</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">StreamProcessing</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../StreamProcessing/1.0_What_Is_Stream_Processing/" class="dropdown-item">1.0 What Is Stream Processing</a>
</li>
                                    
<li>
    <a href="../../../StreamProcessing/2.0.1_EventHubs_Vs_Kafka/" class="dropdown-item">EventHubs Vs Kafka</a>
</li>
                                    
<li>
    <a href="../../../StreamProcessing/2.0.2_Project_Hello_EventHubs/" class="dropdown-item">Overview</a>
</li>
                                    
<li>
    <a href="../../../StreamProcessing/2.0.3_EventHubsLocalEmulator/" class="dropdown-item">Event Hubs Emulator - End to End</a>
</li>
                                    
<li>
    <a href="../../../StreamProcessing/2.0_Azure_EventHubs/" class="dropdown-item">EventHubs</a>
</li>
                                    
<li>
    <a href="../../../StreamProcessing/4_EventProcessingChoices/" class="dropdown-item">Stream Processing Product Combination</a>
</li>
                                    
<li>
    <a href="../../../StreamProcessing/5_AmazonKinesisSparkIntegration/" class="dropdown-item">5 AmazonKinesisSparkIntegration</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Synapse ADF</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../Synapse-ADF/1.0_SynapseConcepts/" class="dropdown-item">SynapseConcepts</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.1_Pools/" class="dropdown-item">Pools</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.3_ETL%20Pipelines/" class="dropdown-item">ETL Pipelines</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.4_Copy-data-tool/" class="dropdown-item">ADF Copy task - When to use</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.5_IntegrationRuntime/" class="dropdown-item">Integration Runtime</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.6_DB_Types_In_Synapse/" class="dropdown-item">Types of DB in Synapse</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.7_SynapseLakeDBAndLakehouse/" class="dropdown-item">Lake DB-Lakehouse-Delta Lake</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.8_ADF_SA_Evolution/" class="dropdown-item">ADF & Synapse Evolution</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/1.9_CETAS/" class="dropdown-item">CETAS</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/2.0_Projects/" class="dropdown-item">2.0 Projects</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/2.1_Pipeline-Local-ADLS/" class="dropdown-item">CopyData-LocalToADLS</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/2.2_PySparkWarehouse/" class="dropdown-item">PysparkWarehouse</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/2.3_ADF_RestAPI_Databricks/" class="dropdown-item">2.3 ADF RestAPI Databricks</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/2.4_Monitor_ADF_Pipelines/" class="dropdown-item">ADF Pipelines Monitoring</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/2.5_ADF_Pipeline_Copy/" class="dropdown-item">Export ADF Pipeline</a>
</li>
                                    
<li>
    <a href="../../../Synapse-ADF/Q%26A/" class="dropdown-item">100 Synapse FAQs</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../../Mongodb/3_DockerMongodb/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../4.2_Bitnami_Spark_Cluster/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#ubuntu-python-openjdk-pyspark" class="nav-link">Ubuntu, Python, OpenJDK &amp; PySpark</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#for-busy-people" class="nav-link">For Busy People</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#steps-to-create-the-image-and-container" class="nav-link">Steps to Create the Image and Container</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#details-of-the-container" class="nav-link">Details of the container</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#debian-downloaded-python-pyspark-no-venv" class="nav-link">Debian, Downloaded Python, Pyspark - no venv.</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#steps-to-create-the-image-and-container_1" class="nav-link">Steps to Create the Image and Container</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#configuration-reference" class="nav-link">Configuration Reference</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<details open markdown="block">
  <summary>
    Table of contents
  </summary>
  {: .text-delta }
1. TOC
{:toc}
</details>

<h1 id="ubuntu-python-openjdk-pyspark"><span style="font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #AD49B3;"><strong>Ubuntu, Python, OpenJDK &amp; PySpark</strong></span></h1>
<p>In this article I will show you how to create Docker containers with Pyspark and Spark components.</p>
<h2 id="for-busy-people"><span style="color: #682A6E; font-family: Segoe UI, sans-serif;letter-spacing: 1px;">For Busy People</span></h2>
<ol>
<li>Save the <a href="#dockerfile">Dockerfile</a> content as <code>Dockerfile</code> (no extension).</li>
<li><code>cd</code> to the folder containtng  the Dockerfile</li>
<li><strong>Run Commands</strong>:
   <code>sh
   docker build -t ubuntu-pyspark .
   docker run -it --name Ubuntu-PySpark --network dasnet ubuntu-pyspark</code></li>
</ol>
<p>Thatâ€™s it!</p>
<h2 id="steps-to-create-the-image-and-container"><span style="color: #682A6E; font-family: Segoe UI, sans-serif;letter-spacing: 1px;">Steps to Create the Image and Container</span></h2>
<p>In this article I will show you how to create a single container with Ubuntu OS, Python and PySpark. We will use just a dockerfile to create it.</p>
<p>Follow the steps below to create the container.</p>
<h3 id="create-the-dockerfile"><span style="color: #682A6E; font-family: Segoe UI, sans-serif;letter-spacing: 1px;">Create the Dockerfile</span></h3>
<p>In a folder create a file <strong>Dockerfile</strong>(No extension) with the content below.</p>
<details open markdown="block">
  <summary>
   Dockerfile
  </summary>


<pre><code class="language-Dockerfile"># Use Ubuntu 20.04 as the base image to avoid &quot;externally-managed-environment&quot; restrictions
FROM ubuntu:20.04

# Set environment variable to avoid interactive prompts during package installation
ENV DEBIAN_FRONTEND=noninteractive

# Update the package list to ensure we have the latest information about available packages
RUN apt-get update

# Install necessary packages including curl, sudo, and nano
RUN apt-get install -y curl sudo nano software-properties-common

# Add the 'deadsnakes' PPA (Personal Package Archive) to access newer Python versions
RUN add-apt-repository ppa:deadsnakes/ppa

# Add the OpenJDK PPA to get the latest JDK versions
RUN add-apt-repository ppa:openjdk-r/ppa

# Update the package list again to include the new PPAs
RUN apt-get update

# Install Python 3.12, pip, and OpenJDK 17
RUN apt-get install -y python3.12 python3-pip openjdk-17-jdk-headless

# Install the PySpark library using pip
RUN pip3 install pyspark

# Clean up the package lists to reduce the image size
RUN apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*

# Create a root user and set its password
RUN echo 'root:Passw0rd' | chpasswd

# Create a new user 'dwdas', set a password, and add this user to the sudo group
RUN useradd -ms /bin/bash dwdas &amp;&amp; echo 'dwdas:Passw0rd' | chpasswd &amp;&amp; adduser dwdas sudo

# Allow the 'dwdas' user to run sudo commands without a password
RUN echo 'dwdas ALL=(ALL) NOPASSWD:ALL' &gt;&gt; /etc/sudoers

# Set the working directory to the home directory of the new user
WORKDIR /home/dwdas

# Switch to the new user 'dwdas'
USER dwdas

# Expose port 8888, commonly used for Jupyter Notebook, if needed
EXPOSE 8888

# Set the default command to start a bash shell
CMD [&quot;bash&quot;]
</code></pre>

</details>

<h3 id="build-the-image"><span style="color: #682A6E; font-family: Segoe UI, sans-serif;letter-spacing: 1px;">Build the Image</span></h3>
<p>Open CMD, navigate to the folder with the Dockerfile, and run:</p>
<pre><code class="language-sh">docker build -t ubuntu-pyspark-img .
</code></pre>
<p>After successfully running the command, you will see an image in your Docker Desktop app:</p>
<h3 id="run-the-docker-container"><span style="color: #682A6E; font-family: Segoe UI, sans-serif;letter-spacing: 1px;">Run the Docker Container</span></h3>
<p>In command prompt, run:</p>
<pre><code class="language-sh">docker run -it --name Debian-PySpark --network dasnet debian-pyspark
</code></pre>
<p>This will create a container with the image we created earlier and start it. You can see it from the Container section of your Docker window.</p>
<p><img src="images/2024-09-05-21-09-01.png" style="
    border: 2px solid gray;
    border-radius: 6px;
    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.2);
    margin: 20px;
    padding: 1px;
    width: Auto; /* Maintain aspect ratio */
    height: Auto; /* Maintain aspect ratio */
   "/></p>
<h2 id="details-of-the-container"><span style="color: #682A6E; font-family: Segoe UI, sans-serif;letter-spacing: 1px;">Details of the container</span></h2>
<p>Here are the details of the installed components. The table will be a handy reference to know which components are installed and important locations, variables etc.</p>
<table>
<thead>
<tr>
<th><strong>Component</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Base Image</strong></td>
<td><code>ubuntu:20.04</code></td>
</tr>
<tr>
<td><strong>Python Version</strong></td>
<td>Python 3.12, installed via the <code>deadsnakes</code> PPA</td>
</tr>
<tr>
<td><strong>Java Version</strong></td>
<td>OpenJDK 17 (Headless), installed via the <code>openjdk-r</code> PPA</td>
</tr>
<tr>
<td><strong>PySpark Version</strong></td>
<td>Latest version of PySpark installed via pip</td>
</tr>
<tr>
<td><strong>Home Directory for User</strong></td>
<td><code>/home/dwdas</code></td>
</tr>
<tr>
<td><strong>Spark Home</strong></td>
<td><code>/opt/bitnami/spark</code></td>
</tr>
<tr>
<td><strong>Java Home</strong></td>
<td><code>/opt/bitnami/java</code></td>
</tr>
<tr>
<td><strong>Python Path</strong></td>
<td><code>/opt/bitnami/spark/python/</code> (for PySpark integration)</td>
</tr>
<tr>
<td><strong>Spark Configuration Directory</strong></td>
<td><code>/opt/bitnami/spark/conf</code></td>
</tr>
<tr>
<td><strong>Spark Worker Directory</strong></td>
<td><code>/opt/bitnami/spark/work</code></td>
</tr>
<tr>
<td><strong>Environment Variables</strong></td>
<td><code>DEBIAN_FRONTEND=noninteractive</code> to avoid interactive prompts during installation</td>
</tr>
<tr>
<td><strong>User Created</strong></td>
<td><code>dwdas</code> with sudo privileges and passwordless sudo access</td>
</tr>
<tr>
<td><strong>Exposed Port</strong></td>
<td>Port <code>8888</code>, commonly used for Jupyter Notebooks</td>
</tr>
<tr>
<td><strong>Default Command</strong></td>
<td><code>bash</code> shell set as the default command</td>
</tr>
<tr>
<td><strong>Network Configuration</strong></td>
<td>Connected to the <code>dasnet</code> network</td>
</tr>
<tr>
<td><strong>Spark Ports</strong></td>
<td>Spark Master: <code>7077</code> (mapped to host port <code>17077</code>), Spark Master UI: <code>8080</code> (mapped to host port <code>16080</code>), Spark Worker UI: <code>8081</code> (mapped to host port <code>16002</code>), <code>8082</code> (mapped to host port <code>16004</code>)</td>
</tr>
</tbody>
</table>
<h3 id="error-package-not-found-404-not-found"><span style="color: #682A6E; font-family: Segoe UI, sans-serif;letter-spacing: 1px;">Error: Package Not Found (404 Not Found)</span></h3>
<p>When building the Docker image, I got a <code>404 Not Found</code> error because some packages like <code>python3.12</code> and <code>openjdk-17-jdk-headless</code> couldn't be found. This usually happens if the package lists are outdated or there's an issue with the repositories. Here's how to fix it:</p>
<ol>
<li>
<p><strong>Update Package Lists</strong>: Run <code>apt-get update</code> first to make sure your package lists are current.</p>
</li>
<li>
<p><strong>Add Correct PPAs</strong>: Update the Dockerfile to include these PPAs:</p>
</li>
<li><code>deadsnakes</code> for Python.</li>
<li>
<p><code>openjdk-r</code> for OpenJDK.</p>
</li>
<li>
<p><strong>Use <code>--fix-missing</code> Option</strong>: If the problem continues, try <code>apt-get install --fix-missing</code> to fix missing packages.</p>
</li>
<li>
<p><strong>Install Specific Versions</strong>: If the latest version isn't available, try installing a slightly older but stable version.</p>
</li>
</ol>
<h1 id="debian-downloaded-python-pyspark-no-venv"><span style="font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #1434CB;"><strong>Debian, Downloaded Python, Pyspark - no venv.</strong></span></h1>
<p>This Section shows you how to create a Docker container with the latest Debian, Python 3.11, OpenJDK 17, and PySpark. Weâ€™ll set up a root user and a named user with essential environment variables.</p>
<p>Note: If you install python using  apt-get install in new Debain it will ask you to install in venv mode. We want to avoid this. Hence we download it(weget) then intstall it manually.</p>
<p>Weâ€™ll use a Dockerfile and docker-compose.yml for the setup.</p>
<h2 id="steps-to-create-the-image-and-container_1"><span style="font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #485BDA;">Steps to Create the Image and Container</span></h2>
<h3 id="create-a-dockerfile"><span style="font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #485BDA;">Create a Dockerfile:</span></h3>
<p>Create a <strong>Dockerfile.txt</strong> with the contents below and <strong>remove the .txt</strong> extension</p>
<details open markdown="block">
  <summary>
   Dockerfile
  </summary>


<pre><code class="language-dockerfile">  # Use Debian as the base image
  FROM debian:latest

  # Set environment variable to avoid interactive prompts during package installation
  ENV DEBIAN_FRONTEND=noninteractive

  # Update the package lists and install essential packages
  RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \
    curl \
    wget \
    tar \
    bash \
    ca-certificates \
    sudo \
    build-essential \
    libssl-dev \
    zlib1g-dev \
    libbz2-dev \
    libreadline-dev \
    libsqlite3-dev \
    libffi-dev

  # Copy the Python source tarball into the image
  COPY Python-3.11.9.tgz /tmp/

  # Extract, build, and install Python 3.11.9
  RUN cd /tmp &amp;&amp; \
      tar -xvf Python-3.11.9.tgz &amp;&amp; \
      cd Python-3.11.9 &amp;&amp; \
      ./configure --enable-optimizations &amp;&amp; \
      make -j 8 &amp;&amp; \
      make altinstall &amp;&amp; \
      cd .. &amp;&amp; \
      rm -rf Python-3.11.9 Python-3.11.9.tgz

  # Create symbolic links for python, python3, pip, and pip3
  RUN ln -s /usr/local/bin/python3.11 /usr/bin/python &amp;&amp; \
      ln -s /usr/local/bin/python3.11 /usr/bin/python3 &amp;&amp; \
      ln -s /usr/local/bin/pip3.11 /usr/bin/pip &amp;&amp; \
      ln -s /usr/local/bin/pip3.11 /usr/bin/pip3

  # Install OpenJDK 17
  RUN apt-get install -y openjdk-17-jdk-headless

  # Install the PySpark library using pip
  RUN python3.11 -m pip install pyspark

  # Set environment variables
  ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
  ENV PYTHONPATH=/usr/local/lib/python3.11/dist-packages
  ENV PYSPARK_PYTHON=/usr/local/bin/python3.11
  ENV PATH=$PATH:$JAVA_HOME/bin

  # Clean up the package lists to reduce the image size
  RUN apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*

  # Create a root user and set its password
  RUN echo 'root:Passw0rd' | chpasswd

  # Create a new user 'dwdas', set a password, and add this user to the sudo group
  RUN useradd -ms /bin/bash dwdas &amp;&amp; echo 'dwdas:Passw0rd' | chpasswd &amp;&amp; adduser dwdas sudo

  # Allow the 'dwdas' user to run sudo commands without a password
  RUN echo 'dwdas ALL=(ALL) NOPASSWD:ALL' &gt;&gt; /etc/sudoers

  # Set the working directory to the home directory of the new user
  WORKDIR /home/dwdas

  # Switch to the new user 'dwdas'
  USER dwdas

  # Expose port 8888, commonly used for Jupyter Notebook, if needed
  EXPOSE 8888

  # Set the default command to start a bash shell
  CMD [&quot;bash&quot;]
  ```
&lt;/details&gt;




### &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #485BDA;&quot;&gt;Download  Python and place in the same folder&lt;/span&gt;

Download Python 3.11.9 from [this site](https://www.python.org/ftp/python/3.11.9/Python-3.11.9.tgz) and place it in the same directory.

### &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #485BDA;&quot;&gt;Build the Docker Image:&lt;/span&gt;
   - Open a terminal and navigate to the directory containing the Dockerfile.
   - Run the following command to build the Docker image:

     ```bash
     docker build -t my-debian-pyspark .
     ```

### &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #485BDA;&quot;&gt;Run the Docker Container:&lt;/span&gt;
   - Once the image is built, run the container using the command:

     ```bash
     docker run -it --name my-debian-pyspark-container my-debian-pyspark
     ```

## &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #485BDA;&quot;&gt;Details of the Container&lt;/span&gt;
| **Category**             | **Details**                                                                                     |
|--------------------------|-------------------------------------------------------------------------------------------------|
| **Base Image**            | Debian (latest)                                                                                 |
| **Python Version**        | Python 3.11.9                                                                                   |
| **Java Version**          | OpenJDK 17                                                                                      |
| **PySpark Version**       | Latest via pip                                                                                  |
| **Environment Variables** | `JAVA_HOME`: `/usr/lib/jvm/java-17-openjdk-amd64`, `PYTHONPATH`: `/usr/local/lib/python3.11/dist-packages`, `PYSPARK_PYTHON`: `/usr/local/bin/python3.11`, `PATH`: `$PATH:$JAVA_HOME/bin` |
| **Installed Packages**    | Build tools (curl, wget, tar, etc.), Python 3.11.9 (source), OpenJDK 17, PySpark (pip)           |
| **User Configuration**    | Root user &amp; `dwdas` (password: `Passw0rd`, sudo access)                                         |
| **Exposed Port**          | 8888 (for Jupyter)                                                                              |
| **Default Command**       | Bash shell start                                                                                |


# &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #006600;&quot;&gt;**Debian, Pip Python, Pip Pyspark - venv.**&lt;/span&gt;

This section shows you how to create a Docker container with the latest Debian, Python 3.11, OpenJDK 17, and PySpark using the recommended venv approach. Weâ€™ll set up a root user and a named user with essential environment variables.

Note: Newer Debian versions enforce using venv for pip install. We will install Python using apt-get and set up venv from the command line.

Weâ€™ll use a Dockerfile and docker-compose.yml for the setup.

## &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #006600;&quot;&gt;Steps to Create the  Container&lt;/span&gt;

### &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #006600;&quot;&gt;Create a Dockerfile:&lt;/span&gt;
   - Create a Dockerfile with the following content:



&lt;details open markdown=&quot;block&quot;&gt;
  &lt;summary&gt;
   Dockerfile
  &lt;/summary&gt;


  ```dockerfile
  # Use the latest version of Debian as the base image
  FROM debian:latest

  # Set environment variable to avoid interactive prompts during package installation
  ENV DEBIAN_FRONTEND=noninteractive

  # Update the package lists and install essential packages
  RUN apt-get update &amp;&amp; \
      apt-get install -y curl wget tar bash ca-certificates sudo gnupg

  # Install Python 3.11, venv, pip, and OpenJDK 17
  RUN apt-get install -y python3.11 python3.11-venv python3.11-dev python3-pip openjdk-17-jdk-headless

  # Create a virtual environment
  RUN python3.11 -m venv /opt/venv

  # Activate the virtual environment and install PySpark
  RUN /opt/venv/bin/python -m pip install pyspark

  # Set environment variables
  ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
  ENV PYTHONPATH=/opt/venv/lib/python3.11/site-packages
  ENV PYSPARK_PYTHON=/opt/venv/bin/python
  ENV PATH=$PATH:$JAVA_HOME/bin:/opt/venv/bin

  # Clean up the package lists to reduce the image size
  RUN apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*

  # Create a root user and set its password
  RUN echo 'root:Passw0rd' | chpasswd

  # Create a new user 'dwdas', set a password, and add this user to the sudo group
  RUN useradd -ms /bin/bash dwdas &amp;&amp; echo 'dwdas:Passw0rd' | chpasswd &amp;&amp; adduser dwdas sudo

  # Allow the 'dwdas' user to run sudo commands without a password
  RUN echo 'dwdas ALL=(ALL) NOPASSWD:ALL' &gt;&gt; /etc/sudoers

  # Set the working directory to the home directory of the new user
  WORKDIR /home/dwdas

  # Switch to the new user 'dwdas'
  USER dwdas

  # Expose port 8888, commonly used for Jupyter Notebook, if needed
  EXPOSE 8888

  # Set the default command to start a bash shell
  CMD [&quot;bash&quot;]
  ```
&lt;/details&gt;


















### &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #006600;&quot;&gt;Build the Docker Image:&lt;/span&gt;
   - Open a terminal and navigate to the directory containing the Dockerfile.
   - Run the following command to build the Docker image:

     ```bash
     docker build -t my-debian-pyspark-venv .
     ```

### &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #006600;&quot;&gt;Run the Docker Container:&lt;/span&gt;
   - Once the image is built, run the container using the command:

     ```bash
     docker run -it --name my-debian-pyspark-venv-container my-debian-pyspark-venv
     ```

## &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #006600;&quot;&gt;Details of the Container&lt;/span&gt;

| **Category**             | **Details**                                                                                                              |
|--------------------------|--------------------------------------------------------------------------------------------------------------------------|
| **Base Image**            | Debian (latest)                                                                                                          |
| **Python Version**        | Python 3.11.9                                                                                                            |
| **Java Version**          | OpenJDK 17                                                                                                               |
| **PySpark Version**       | Installed via pip in a virtual environment                                                                                |
| **Virtual Environment**   | Created with `python3.11 -m venv /opt/venv`                                                                              |
| **Environment Variables** | `JAVA_HOME`: `/usr/lib/jvm/java-17-openjdk-amd64`, `PYTHONPATH`: `/opt/venv/lib/python3.11/site-packages`, `PYSPARK_PYTHON`: `/opt/venv/bin/python`, `PATH`: `$PATH:$JAVA_HOME/bin:/opt/venv/bin` |
| **Installed Packages**    | Essential tools (curl, wget, tar, bash, etc.), Python 3.11, venv, pip, OpenJDK 17, PySpark (in venv)                     |
| **User Configuration**    | Root user &amp; `dwdas` (password: `Passw0rd`, sudo access)                                                                  |
| **Exposed Port**          | 8888 (for Jupyter)                                                                                                       |
| **Default Command**       | Bash shell start                                                                                                         |



To modify the setup so that the `conf` directory in the Spark container is mapped to a local folder on your machine (and the folder is auto-created), we need to update the `docker run` command to include a volume mapping. 

# &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #C22E2E;&quot;&gt;**Single-Node Bitnami Spark With Master and Worker**&lt;/span&gt;


Here, we will use the official Bitnami Spark Docker image to set up a single-node Spark environment. This setup will include both the Master and Worker.

## &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #C22E2E;&quot;&gt;Steps to create the container&lt;/span&gt;

You can either download, unzip, and run the `.bat` file from [this link](Dockerfiles/Bitnami_Spark_SingleNode_GOLD.zip) to create the entire container. Or, you can follow the steps manually. Both methods will give the same result.

### &lt;span style=&quot;font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #C22E2E;&quot;&gt;Create a Custom Dockerfile&lt;/span&gt;

In your folder create a file Dockerfile(no extension) with the following content:





&lt;details open markdown=&quot;block&quot;&gt;
  &lt;summary&gt;
   Dockerfile
  &lt;/summary&gt;

```dockerfile
# Use the official Bitnami Spark image as the base. I always pull a constant image and not :latest.
FROM bitnami/spark:3.5.2-debian-12-r2

# Step 1: Switch to root user to install software
# We need to be root to install utilities and set up sudo permissions.
USER root

# Step 2: Update the package list and install utilities. py4j and ipykernel is for VS studio connection.
# Install common utilities like sudo, ping, and nano.
# Update the base system
RUN apt-get update &amp;&amp; \
    apt-get install -y sudo nano iputils-ping grep curl wget vim net-tools procps lsof telnet &amp;&amp; \
    apt-get clean

# Install pip (if not already installed)
RUN apt-get install -y python3-pip

# Install py4j and ipykernel using pip. Required VS Code connection.
RUN pip3 install py4j ipykernel

# Step 3: Set the root user password to 'Passw0rd'
# This sets the root password to 'Passw0rd' for future access.
RUN echo &quot;root:Passw0rd&quot; | chpasswd

# Step 4: Give sudo privileges to the 'spark' user
# Here, we are allowing the 'spark' user to run commands as sudo without a password.
RUN echo &quot;spark ALL=(ALL) NOPASSWD: ALL&quot; &gt;&gt; /etc/sudoers

# After finishing the setup, we dont switch back to any user. The bitnami original Dockerfile switches to user 1001 and the directory is /opt/bitnami/spark

# Step 6: Expose necessary ports for Spark Web UI and communication
# 4040: Spark Worker Web UI
# 7077: Spark Master communication
# 8080: Spark Master Web UI
EXPOSE 4040 7077 8080

# End of the Dockerfile
</code></pre>

</details>

<h3 id="create-a-local-conf-directory"><span style="font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #C22E2E;">Create a Local <code>conf</code> Directory</span></h3>
<p>Before running the container, create a folder named <code>local-spark-conf</code> in the same folder where your Dockerfiles are. This folder will store the configuration files and will be mapped to the <code>conf</code> directory inside the container.</p>
<pre><code class="language-bash">mkdir local-spark-conf
</code></pre>
<h3 id="build-the-docker-image"><span style="font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #C22E2E;"> Build the Docker Image</span></h3>
<p>Once the Dockerfile is ready, you can build the Docker image with the following command:</p>
<pre><code class="language-bash">docker build -t bitnami-spark-single-node .
</code></pre>
<p>This command will create a Docker image called <code>bitnami-spark-single-node</code> using the Dockerfile you just created.</p>
<h3 id="run-the-container-and-map-the-conf-directory"><span style="font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #C22E2E;">Run the Container and Map the <code>conf</code> Directory</span></h3>
<p>Now, we run the Spark container with the <code>conf</code> directory mapped to the local folder you created earlier. If the folder doesnâ€™t exist, Docker will create it.</p>
<pre><code class="language-bash">docker run -d --network dasnet --name bitnami-spark-single-node -p 4040:4040 -p 8080:8080 -p 7077:7077 -v ./local-spark-conf:/opt/spark/conf bitnami-spark-single-node
</code></pre>
<h2 id="configuration-reference"><span style="font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #C22E2E;">Configuration Reference</span></h2>
<p>Here is a list of some components in this environment. The list is compiled from the official bitnami spark github <a href="https://github.com/bitnami/containers/blob/main/bitnami/spark/README.md">page</a>.</p>
<h3 id="environment-details"><span style="font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #C22E2E;">Environment Details</span></h3>
<table>
<thead>
<tr>
<th><strong>Component</strong></th>
<th><strong>Value</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>OS</strong></td>
<td>debian 12: bitnami/minideb:bookworm</td>
</tr>
<tr>
<td><strong>Python</strong></td>
<td>python-3.12.5-1: /opt/bitnami/python/bin/python</td>
</tr>
<tr>
<td><strong>PYTHONPATH</strong></td>
<td>/opt/bitnami/spark/python/</td>
</tr>
<tr>
<td><strong>Java</strong></td>
<td>java-17.0.12-10-1: JAVA_HOME = /opt/bitnami/java</td>
</tr>
<tr>
<td><strong>JAVA_HOME</strong></td>
<td>/opt/bitnami/java</td>
</tr>
<tr>
<td><strong>SPARK_HOME</strong></td>
<td>/opt/bitnami/spark</td>
</tr>
<tr>
<td><strong>SPARK_USER</strong></td>
<td>spark</td>
</tr>
<tr>
<td><strong>SPARK JARS Location for Installing External Jars</strong></td>
<td>/opt/bitnami/spark/jars</td>
</tr>
<tr>
<td><strong>Workdir</strong></td>
<td>/opt/bitnami/spark</td>
</tr>
<tr>
<td><strong>User</strong></td>
<td>1001</td>
</tr>
<tr>
<td><strong>Entrypoint</strong></td>
<td>/opt/bitnami/scripts/spark/entrypoint.sh</td>
</tr>
<tr>
<td><strong>Command</strong></td>
<td>/opt/bitnami/scripts/spark/run.sh</td>
</tr>
<tr>
<td><strong>Certificates</strong></td>
<td>/opt/bitnami/spark/conf/certs</td>
</tr>
<tr>
<td><strong>SPARK_SSL_KEYSTORE_FILE</strong></td>
<td>/opt/bitnami/spark/conf/certs/spark-keystore.jks</td>
</tr>
<tr>
<td><strong>SPARK_MODE</strong></td>
<td>master</td>
</tr>
<tr>
<td><strong>SPARK_MASTER_URL</strong></td>
<td>spark://spark-master:7077</td>
</tr>
<tr>
<td><strong>SPARK_SSL_ENABLED</strong></td>
<td>no</td>
</tr>
<tr>
<td><strong>Docker Logs Command</strong></td>
<td>docker logs bitnami-spark-single-node</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Note: The Dockerfile also install py4j and ipykernel. These are reuqired for VS code to container using remote containers extension.</p>
</blockquote>
<h3 id="read-only-environment-variables-official-bitnami-github"><span style="font-family: 'Segoe UI', sans-serif; letter-spacing: 1px;color: #C22E2E;">Read-only Environment Variables (<a href="https://github.com/bitnami/containers/blob/main/bitnami/spark/README.md">Official Bitnami github</a>)</span></h3>
<table>
<thead>
<tr>
<th><strong>Name</strong></th>
<th><strong>Description</strong></th>
<th><strong>Value</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>SPARK_BASE_DIR</strong></td>
<td>Spark installation directory.</td>
<td>${BITNAMI_ROOT_DIR}/spark</td>
</tr>
<tr>
<td><strong>SPARK_CONF_DIR</strong></td>
<td>Spark configuration directory.</td>
<td>${SPARK_BASE_DIR}/conf</td>
</tr>
<tr>
<td><strong>SPARK_DEFAULT_CONF_DIR</strong></td>
<td>Spark default configuration directory.</td>
<td>${SPARK_BASE_DIR}/conf.default</td>
</tr>
<tr>
<td><strong>SPARK_WORK_DIR</strong></td>
<td>Spark workspace directory.</td>
<td>${SPARK_BASE_DIR}/work</td>
</tr>
<tr>
<td><strong>SPARK_CONF_FILE</strong></td>
<td>Spark configuration file path.</td>
<td>${SPARK_CONF_DIR}/spark-defaults.conf</td>
</tr>
<tr>
<td><strong>SPARK_LOG_DIR</strong></td>
<td>Spark logs directory.</td>
<td>${SPARK_BASE_DIR}/logs</td>
</tr>
<tr>
<td><strong>SPARK_TMP_DIR</strong></td>
<td>Spark tmp directory.</td>
<td>${SPARK_BASE_DIR}/tmp</td>
</tr>
<tr>
<td><strong>SPARK_JARS_DIR</strong></td>
<td>Spark jar directory.</td>
<td>${SPARK_BASE_DIR}/jars</td>
</tr>
<tr>
<td><strong>SPARK_INITSCRIPTS_DIR</strong></td>
<td>Spark init scripts directory.</td>
<td>/docker-entrypoint-initdb.d</td>
</tr>
<tr>
<td><strong>SPARK_USER</strong></td>
<td>Spark user.</td>
<td>spark</td>
</tr>
<tr>
<td><strong>SPARK_DAEMON_USER</strong></td>
<td>Spark system user.</td>
<td>spark</td>
</tr>
<tr>
<td><strong>SPARK_DAEMON_GROUP</strong></td>
<td>Spark system group.</td>
<td>spark</td>
</tr>
</tbody>
</table></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../../../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../js/base.js"></script>
        <script src="../../../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
