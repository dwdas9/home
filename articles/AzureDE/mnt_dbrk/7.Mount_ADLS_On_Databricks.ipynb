{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e19cc36c-8d10-4716-915d-d610e732758b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Mounting ADLS Gen2 on Databricks using AAD OAuth & Service Principal\n",
    "\n",
    "Integrating Databricks with Azure Data Lake Storage Gen2 (ADLS Gen2) through Azure Active Directory (AAD) OAuth and service principal provides a secure data access method. This tutorial quickly guides you through mounting ADLS Gen2 storage to the Databricks File System (DBFS).\n",
    "\n",
    "### Quick Steps:\n",
    "\n",
    "1. **Azure Setup**:\n",
    "   - Have an ADLS Gen2 storage account.\n",
    "   - Set up a service principal in Azure AD.\n",
    "\n",
    "| Step | Action | Details |\n",
    "|------|--------|---------|\n",
    "| 1 | **Azure Portal** | Navigate to [Azure Portal](https://portal.azure.com/). |\n",
    "| 2 | **Azure AD** | Select \"Azure Active Directory\" > \"App registrations\". |\n",
    "| 3 | **New Registration** | Click \"+ New registration\". |\n",
    "| 4 | **Details** | Provide a name, select account type, and set the redirect URI (if needed). |\n",
    "| 5 | **Register** | Click \"Register\". Note down the Application (client) ID. |\n",
    "| 6 | **Certificates & secrets** | Under \"Manage\", select \"Certificates & secrets\". |\n",
    "| 7 | **New Client Secret** | Click \"+ New client secret\". Provide a description and select the expiration. |\n",
    "| 8 | **Save Secret** | After adding, save the value of the client secret. <br> **To Azure Key Vault:** <table><tr><td>1. **Navigate**</td><td>Go to Azure Key Vault in the portal.</td></tr><tr><td>2. **Select or Create**</td><td>Choose an existing vault or create a new one.</td></tr><tr><td>3. **Secrets Section**</td><td>Click on \"Secrets\" in the left pane.</td></tr><tr><td>4. **+ Generate/Import**</td><td>Add the new secret, give it a name and paste the value.</td></tr></table> |\n",
    "\n",
    "  - Make sure to properly set permissions on the Key Vault to allow the necessary entities (like applications or users) to access the secret.\n",
    "  - Remember to store the client secret securely; it's displayed only once.\n",
    "\n",
    "   - Grant `Storage Blob Data Contributor` role to the service principal on the storage.\n",
    "\n",
    "2. **Fetch Credentials**:\n",
    "   <sub>Use Databricks secrets for security.</sub>\n",
    "   ```python\n",
    "   clientID = dbutils.secrets.get(scope=\"azbackedscope\", key=\"regappClientID\")\n",
    "   clientSecret = dbutils.secrets.get(scope=\"azbackedscope\", key=\"regappClientSecret\")\n",
    "   directoryID = dbutils.secrets.get(scope=\"azbackedscope\", key=\"regappDirectoryID\")\n",
    "   ```\n",
    "\n",
    "3. **Set OAuth Configs**:\n",
    "   <sub>Prepare OAuth authentication dictionary.</sub>\n",
    "   ```python\n",
    "   configs = {\n",
    "       \"fs.azure.account.auth.type\": \"OAuth\",\n",
    "       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "       \"fs.azure.account.oauth2.client.id\": clientID,\n",
    "       \"fs.azure.account.oauth2.client.secret\": clientSecret,\n",
    "       \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{directoryID}/oauth2/token\"\n",
    "   }\n",
    "   ```\n",
    "\n",
    "4. **Mount Storage**:\n",
    "   ```python\n",
    "   adlsPath = f\"abfss://{containerName}@{storageAccountName}.dfs.core.windows.net/\"\n",
    "   mountPoint = \"/mnt/your_mount_name\"\n",
    "   \n",
    "   dbutils.fs.mount(\n",
    "       source=adlsPath,\n",
    "       mount_point=mountPoint,\n",
    "       extra_configs=configs\n",
    "   )\n",
    "   ```\n",
    "\n",
    "5. **Check Mount**:\n",
    "   <sub>Validate with a quick file list.</sub>\n",
    "   ```python\n",
    "   display(dbutils.fs.ls(mountPoint))\n",
    "   ```\n",
    "### Conclusion:\n",
    "\n",
    "With the ADLS Gen2 storage now mounted on DBFS, you can easily read/write data using the DBFS path, offering a streamlined and secure way to integrate Databricks with ADLS Gen2 using Azure Active Directory (AAD) OAuth authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e33485e-e335-46f0-9fab-a3720c62436f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is designed to mount Azure Data Lake Storage Gen2 (ADLS Gen2) into the Databricks File System.\n",
    "ADLS Gen2 is accessed using the `abfss` scheme which denotes Azure Blob File System with SSL.\n",
    "The script employs Azure Active Directory (AAD) OAuth authentication leveraging a service principal.\n",
    "\"\"\"\n",
    "# Define the Azure Data Lake Storage Gen2 account details.\n",
    "storageAccountName = \"saforone\"\n",
    "containerName = \"demo\"\n",
    "fileName = \"circuits.csv\"\n",
    "\n",
    "# Fetch the service principal credentials from a Databricks secret scope linked to Azure Key Vault.\n",
    "clientID = dbutils.secrets.get(scope=\"azbackedscope\", key=\"regappClientID\")\n",
    "clientSecret = dbutils.secrets.get(scope=\"azbackedscope\", key=\"regappClientSecret\")\n",
    "directoryID = dbutils.secrets.get(scope=\"azbackedscope\", key=\"regappDirectoryID\")\n",
    "\n",
    "# Construct the full path to the ADLS Gen2 location using the `abfss` scheme.\n",
    "adlsPath = f\"abfss://{containerName}@{storageAccountName}.dfs.core.windows.net/\"\n",
    "\n",
    "# Define the OAuth configurations for accessing ADLS Gen2 - OAuth token provider, service principal credentials and endpoint\n",
    "configs = {\n",
    "    \"fs.azure.account.auth.type\": \"OAuth\",\n",
    "    \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "    \"fs.azure.account.oauth2.client.id\": clientID,\n",
    "    \"fs.azure.account.oauth2.client.secret\": clientSecret,\n",
    "    \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{directoryID}/oauth2/token\"\n",
    "}\n",
    "\n",
    "# Define the Databricks mount point. Note: mount points in Databricks should always start with \"/mnt/\".\n",
    "mountPoint = \"/mnt/forone/demo\"\n",
    "\n",
    "# Mount ADLS Gen2 storage to the Databricks File System.\n",
    "dbutils.fs.mount(\n",
    "  source=adlsPath,\n",
    "  mount_point=mountPoint,\n",
    "  extra_configs=configs\n",
    ")\n",
    "\n",
    "# Display the contents of the mounted ADLS Gen2 location.\n",
    "display(dbutils.fs.ls(mountPoint))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "7.Mount_ADLS_On_Databricks",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
