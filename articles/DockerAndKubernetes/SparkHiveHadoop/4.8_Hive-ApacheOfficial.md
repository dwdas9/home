---
layout: default
title: Hive-Official-Docker-Setup
parent: spark-hive-hadoop
grand_parent: Docker
nav_order: 8
---

- [Hive Metastore and HiveServer2 Setup On Docker](#hive-metastore-and-hiveserver2-setup-on-docker)
  - [Overview](#overview)
  - [Quick Step](#quick-step)
  - [Step 1: Download the Required JDBC Driver](#step-1-download-the-required-jdbc-driver)
  - [Step 2: Run the PostgreSQL Service](#step-2-run-the-postgresql-service)
  - [Step 3: Run the Metastore Service](#step-3-run-the-metastore-service)
  - [Step 4: Run the HiveServer2 Service](#step-4-run-the-hiveserver2-service)
  - [Step 5: Verify the Services](#step-5-verify-the-services)
  - [Step 6: Connecting and Testing](#step-6-connecting-and-testing)
- [Connecting the system to Spark](#connecting-the-system-to-spark)
- [Configuration Reference](#configuration-reference)


# Hive Metastore and HiveServer2 Setup On Docker

## Overview
This guide will help you set up a Hive Metastore and HiveServer2 using Docker on the `dasnet` network. You will download the required PostgreSQL JDBC driver, place it in the current directory, and then run three Docker commands to start the PostgreSQL, Metastore, and HiveServer2 services.

> This steup is based on [Official Hive docker site](https://hive.apache.org/developement/quickstart/). There is almost no customization, except the addtion of network dasnet.

> The only issue with this setup is that restarting HiveServer2 will result in the error: "HiveServer2 running as process 7. Stop it first." Apart from that it's an excellent setup. But, you have to rerun hiveserver2 from scracth everytime. metastore and postgres combination works fine always. No need of restart.

## Quick Step

Just download the [zip file](Dockerfiles/Hive-ApacheOfficial-Setup_GOLD.zip). Unzip it and run the run.bat It will create three conatiners like this:

![](images/2024-09-04-01-47-48.png)

## Step 1: Download the Required JDBC Driver
You need to download the PostgreSQL JDBC driver `postgresql-42.5.0.jar`. Place the downloaded JAR file in the current directory where you will run the Docker commands.

You can download the JDBC driver from the official [PostgreSQL JDBC website](https://jdbc.postgresql.org/download.html) or use Maven with the following command:

```bash
mvn dependency:copy -Dartifact="org.postgresql:postgresql:42.5.0" -DoutputDirectory=.
```

## Step 2: Run the PostgreSQL Service
Before starting the Hive Metastore, you need to run a PostgreSQL container. Use the following command:

```bash
docker run -d --network dasnet --name postgres -e POSTGRES_DB=metastore_db -e POSTGRES_USER=hive -e POSTGRES_PASSWORD=password postgres:13
```

This command starts a PostgreSQL container named `postgres` on the `dasnet` network, with a database named `metastore_db`, and the username `hive` with the password `password`.

## Step 3: Run the Metastore Service
Run the following Docker command to start the Hive Metastore service in the current directory:

```bash
docker run -d --network dasnet -p 9083:9083 --env SERVICE_NAME=metastore --env DB_DRIVER=postgres --env SERVICE_OPTS="-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres:5432/metastore_db -Djavax.jdo.option.ConnectionUserName=hive -Djavax.jdo.option.ConnectionPassword=password" --mount source=warehouse,target=/opt/hive/data/warehouse --mount type=bind,source=%cd%\postgresql-42.5.0.jar,target=/opt/hive/lib/postgres.jar --name metastore-standalone apache/hive:4.0.0-alpha-2
```

This command will start the Hive Metastore service on port `9083`. The PostgreSQL JDBC driver will be mounted from the current directory to the container. The service will be named `metastore-standalone`.

## Step 4: Run the HiveServer2 Service
Next, run the following Docker command to start the HiveServer2 service in the current directory:

```bash
docker run -d --network dasnet -p 10000:10000 -p 10002:10002 --env SERVICE_NAME=hiveserver2 --env SERVICE_OPTS="-Dhive.metastore.uris=thrift://metastore:9083" --mount source=warehouse,target=/opt/hive/data/warehouse --env IS_RESUME="true" --name hiveserver2-standalone apache/hive:4.0.0-alpha-2
```

This command will start the HiveServer2 service on ports `10000` and `10002`. The service will connect to the previously started Metastore service and will be named `hiveserver2-standalone`.

## Step 5: Verify the Services
To verify that all services are running, use the following command:

```bash
docker ps
```

You should see the `postgres`, `metastore-standalone`, and `hiveserver2-standalone` containers listed as running.

## Step 6: Connecting and Testing
To create sample tables and see the results in Hive using Beeline, follow these steps:

1. **First, connect to the `hiveserver2` container**:
   
   You can connect to the `hiveserver2` container using Docker's exec command from Docker Desktop's Exec window or the terminal:

   ```bash
   docker exec -it hiveserver2 /bin/bash
   ```

2. **Once inside the container, run Beeline to connect to HiveServer2**:

   After you’re inside the container’s shell, use Beeline to connect to the HiveServer2 instance running on port `10000`:

   ```bash
   beeline -u 'jdbc:hive2://hiveserver2:10000/'
   ```


3. **Create a sample table**:
   Once connected, create a simple table. Here’s an example to create a basic table `sample_table` with two columns (`id` and `name`).

   ```sql
   CREATE TABLE movies (id INT, name STRING);
   ```

4. **Insert sample data**:
   Insert some sample data into the table to test the setup.

   ```sql
   INSERT INTO movies VALUES (1, 'Rambo'), (2, 'Mogambo');
   ```

5. **Query the table**:
   After inserting the data, you can query the table to see the results.

   ```sql
   SELECT * FROM movies;
   ```

   This will display the contents of the `movies` like this:

   ```bash
   +-------------+-------------+
   |    id       |    name     |
   +-------------+-------------+
   |  1          |  Rambo      |
   |  2          |  Mogambo        |
   +-------------+-------------+
   ```

6. **Exit Beeline**:
   Once you're done, you can exit the Beeline session using:

   ```sql
   !quit;
   ```

# Connecting the system to Spark

In this section, we will show how to create a Spark container from scratch and connect it to the existing Hive environment that we already set up using Docker. You will learn step by step how to configure Spark so it can talk to Hive, create tables in Hive, and use PySpark to query and manage those tables.

1. **Create and Run the Spark Container**:
   
   First, we need to create a new Spark container. This Spark container will be on the same network as your Hive and PostgreSQL containers so that they can communicate with each other.

   Run this command to create the Spark container and connect it to the Docker network (`dasnet`):

   ```bash
   docker run -d --network dasnet --name spark-container -p 4040:4040 -p 8080:8080 -v /path/to/spark-conf:/opt/spark/conf bitnami/spark:latest
   ```

2. **Configure Hive for Spark**:
   
   Now, we need to tell Spark where to find Hive. We do this by setting up the `hive-site.xml` file with the correct information about the Hive metastore.

   Here’s what the file should look like:

   ```xml
   <configuration>
     <property>
       <name>hive.metastore.uris</name>
       <value>thrift://metastore:9083</value>
     </property>
     <property>
       <name>javax.jdo.option.ConnectionDriverName</name>
       <value>org.postgresql.Driver</value>
     </property>
     <property>
       <name>javax.jdo.option.ConnectionURL</name>
       <value>jdbc:postgresql://postgres:5432/metastore_db</value>
     </property>
     <property>
       <name>javax.jdo.option.ConnectionUserName</name>
       <value>hive</value>
     </property>
     <property>
       <name>javax.jdo.option.ConnectionPassword</name>
       <value>password</value>
     </property>
   </configuration>
   ```

   Copy this file to your Spark container using:

   ```bash
   docker cp /path/to/hive-site.xml spark-container:/opt/spark/conf/hive-site.xml
   ```

3. **Add PostgreSQL Driver to Spark**:

   Since Hive uses PostgreSQL, you need to add the PostgreSQL driver to the Spark container so that Spark can connect to the Hive metastore.

   Copy the PostgreSQL driver (`postgresql-42.5.1.jar`) into the Spark container:

   ```bash
   docker cp /path/to/postgresql-42.5.1.jar spark-container:/opt/spark/jars/
   ```

4. **Start PySpark with Hive Support**:
   
   Now, start the PySpark session from the Spark container with Hive support enabled:

   ```bash
   docker exec -it spark-container /bin/bash
   pyspark --conf spark.sql.catalogImplementation=hive
   ```

5. **Create and Query Tables Using PySpark**:

   Inside the PySpark shell, you can create tables and query them. Here’s how:

   - **Create a table**:

     ```python
     spark.sql("CREATE TABLE IF NOT EXISTS sample_table (id INT, name STRING)")
     ```

   - **Insert data into the table**:

     ```python
     spark.sql("INSERT INTO sample_table VALUES (1, 'Alice'), (2, 'Bob')")
     ```

   - **Query the table**:

     ```python
     result = spark.sql("SELECT * FROM sample_table")
     result.show()
     ```

6. **Verify the Table in Hive**:

   After creating the table using PySpark, you can check if the table exists in Hive using Beeline:

   ```bash
   docker exec -it hiveserver2 /bin/bash
   beeline -u 'jdbc:hive2://hiveserver2:10000/'
   ```

   Run this query in Beeline to verify:

   ```sql
   SHOW TABLES;
   SELECT * FROM sample_table;
   ```

# Configuration Reference

| Component                        | Details                                                                                                                            |
|-----------------------------------|------------------------------------------------------------------------------------------------------------------------------------|
| **PostgreSQL Hive Metastore**     | - **Database Name**: `metastore_db` <br> - **Username**: `hive` <br> - **Password**: `password` <br> - **Connection URL**: `jdbc:postgresql://postgres:5432/metastore_db` |
| **Schema Tool for Hive Tables**   | - **Location**: `/opt/hive/bin/schematool` <br> - **Command**: `/opt/hive/bin/schematool -dbType postgres -initOrUpgradeSchema`    |
| **Hive Configuration Directory**  | `/opt/hive/conf`                                                                                                                   |
| **Hive Version**                  | `4.0.0-alpha-2`                                                                                                                   |
| **HiveServer2 Startup Script**    | `/opt/hive/bin/ext/hiveserver2.sh`                                                                                                |
| **PostgreSQL Container**          | - **Network**: `dasnet` <br> - **Image**: `postgres:13` <br> - **Command**: `docker run -d --network dasnet --name postgres -e POSTGRES_DB=metastore_db -e POSTGRES_USER=hive -e POSTGRES_PASSWORD=password postgres:13` |
| **Metastore Container**           | - **Network**: `dasnet` <br> - **Port**: `9083` <br> - **Warehouse Data Directory**: `/opt/hive/data/warehouse` <br> - **JDBC Driver**: `/opt/hive/lib/postgres.jar` <br> - **Image**: `apache/hive:4.0.0-alpha-2` <br> - **Command**: `docker run -d --network dasnet -p 9083:9083 --env SERVICE_NAME=metastore --env DB_DRIVER=postgres --env SERVICE_OPTS="-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres:5432/metastore_db -Djavax.jdo.option.ConnectionUserName=hive -Djavax.jdo.option.ConnectionPassword=password" --mount source=warehouse,target=/opt/hive/data/warehouse --mount type=bind,source=%USERPROFILE%\.m2\repository\org\postgresql\postgresql\42.5.1\postgresql-42.5.1.jar,target=/opt/hive/lib/postgres.jar --name metastore apache/hive:4.0.0-alpha-2` |
| **HiveServer2 Container**         | - **Network**: `dasnet` <br> - **Ports**: `10000` (Thrift service), `10002` (additional) <br> - **Warehouse Data Directory**: `/opt/hive/data/warehouse` <br> - **Metastore URI**: `thrift://metastore:9083` <br> - **Image**: `apache/hive:4.0.0-alpha-2` <br> - **Command**: `docker run -d --network dasnet -p 10000:10000 -p 10002:10002 --env SERVICE_NAME=hiveserver2 --env SERVICE_OPTS="-Dhive.metastore.uris=thrift://metastore:9083" --mount source=warehouse,target=/opt/hive/data/warehouse --env IS_RESUME="true" --name hiveserver2 apache/hive:4.0.0-alpha-2` |


> **Note**: This setup works smoothly for the metastore and PostgreSQL combination, but restarting HiveServer2 doesn't work, and you need to recreate the HiveServer2 container alone.

[Official Hive Docker](https://hive.apache.org/developement/quickstart/)
[Hive Files Github](https://github.com/apache/hive)


© 2024 Das. All Rights Reserved.