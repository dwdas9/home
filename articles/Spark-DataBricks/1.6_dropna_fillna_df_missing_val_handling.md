---
layout: default
title: dropna & fillna
parent: Concepts
grand_parent: Spark-Databricks
nav_order: 8
---

<details open markdown="block">
  <summary>
    Table of contents
  </summary>
  {: .text-delta }
1. TOC
{:toc}
</details>

<img src="images/custom-image-2024-07-11-15-39-31.png"  style="
    border: 2px solid gray;
    border-radius: 6px;
    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.2);
    margin: 20px;
    padding: 1px;
    width: auto; /* Maintain aspect ratio */
    height: 500; /* Maintain aspect ratio */
    transition: transform 0.2s;
" />
# <span style="color:blue">dropna & fillna - Handling missing values in dfs</span>

Null values, garbage values in tables/dataframes are very common. Here I will show you how you can remove them or replace them using examples.

## <span style="color:green">1. Dropping Rows with Null Values</span>

- **Drop Rows Where All Values Are Null**:
  ```python
  df.dropna("all")  # or df.na.drop("all")
  ```
  This will drop rows where all values are null.

- **Drop Rows with Any Null Values**:
  ```python
  df.dropna()  # or df.na.drop()
  ```
  This will drop rows that have even one null value.

## <span style="color:purple">2. Filling Missing Values</span>

- **Fill Null Values in Specific Columns**:
  ```python
  df.fillna({"price": 0, "country": "unknown"})
  ```
  If the `price` column has null values, replace them with `0`. If the `country` column has null values, replace them with `"unknown"`.

## <span style="color:orange">3. Replacing Specific Values</span>

- **Replace Null Values in a Specific Column**:
  ```python
  df.replace({None: "godknows"}, subset=["country"])
  ```
  This will replace `None` (null) values in the `country` column with `"godknows"`.

- **Using Conditional Statements**:
  ```python
  from pyspark.sql.functions import when

  df = df.withColumn("country", when(df["country"].isNull(), "godknows").otherwise(df["country"]))
  ```
  This will replace null values in the `country` column with `"godknows"`.

## <span style="color:red">4. Imputation</span>

- **Fill Null Values with Mean of the Column**:
  ```python
  from pyspark.sql.functions import mean

  mean_price = df.select(mean("price")).collect()[0][0]
  df = df.na.fill({"price": mean_price})
  ```
  This will replace null values in the `price` column with the mean value of that column.